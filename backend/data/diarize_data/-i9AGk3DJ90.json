{"text": "Would you rather have an assistant with the intelligence of like Einstein but they have no access to the Internet and they don't know anything about your history or would you like to have an assistant that's just above average intelligence, knows everything about you and they can use the Internet? Okay. You would choose that. Hey, great to have you here in person. Good to be here. I remember when you were right up this hill. Yeah, you guys were over here. So I, I had a couple thoughts this morning. First, I got to take a ride in full self driving 12. How was that? It was mind boggling. I think this is going to be a bit of a chat GPT moment for full self driving. But what it really, it just reminded me of the magic of this moment. Tesla rebuilding their models for how they do self driving around, imitation learning and all this interesting stuff going on over there. Like, you know, I think they probably made more progress in the last 12 months than in the last seven years. Wow. In terms of, in terms of what's going on there and, and it's going to be rolled out here. It's already rolled out to I think 5,000 people. And so like people are going to start experiencing that. And I think we're having more and more of these moments. Right. Because this substrate we're going to talk a lot about today. AI. Yeah. And just to compute like what it unlocks. The second in prepping for this pod was how bad you make my head hurt. The. You know, I was thinking about this. You know what I love about this pod is like it's a forcing function. You know, you and I talk all the time, you're always challenging me, we're always comparing notes. But now with a little bit of structure around it, every couple weeks we have to think about some topics. Today we're going to talk a lot about think AI and compute and chips and its impact on big businesses. And honestly I liken it to an athlete, you know and they say in order to be the best I can possibly be, maybe Kobe, I want to practice against the best. Oh no. But it's like, listen, the reality is it's like running 10 miles a day to get ready for a big game. Like it's like if you're in this business and you're not exhausted with the analysis you're doing, the thinking you're doing, particularly at moments like these to try to gather this data and try to gather edge, then you're probably not going to end up on top of the heap. I agree. And I think that having a topic or an idea that you want to fully flush out and be able to talk about, causes you to place a few phone calls, read a few PDFs, and before you know it, you actually realize you've learned something you didn't know five days earlier. It's a, you know, I think the, the little, you know, pull the screen back a little bit. I mean, you and I have talked, you know, or interacted five, ten times a day over the course of last week on these topics. And then we turn over a rock and we find more data, more information, we share that with one another, it leads to another conversation. You know, and the combined networks allow us to ask a lot of the smartest people in the world the questions we need to be asking to try to figure out this moment. So it's been a lot of fun, but, but it does give me a. Bit of a headache, hopefully a good one. So, so we remain, we remain kind of in earnings season and so what's happened in the past few weeks that you think's super important? Yeah, well, we have a lot of, we have a few stocks that have run a lot Meta Nvidia up 30, 40% even with the pullback that we had today. But the truth is the NASDAQ hasn't really moved that much. I mean, I think we're up 3 or 4% through today. If you look at the median stock, I think it's up about 1%. In fact, I think we have a chart here just on the dispersion that we see in the nasdaq. You know, and so remember last year was, was like this risk on moment, a mean reverting moment for all of technology. And this year we're, we're, we're really starting to see the winners and the losers. We have some software companies that reported after the bell tonight that are down a lot because they're not seeing the AI pull forward that maybe an Amazon or a Microsoft. So that's my first takeaway. My second takeaway is, you know, against these higher prices for some of these companies, you know, the backdrop looks a little bit more challenging. So we had a CPI print that came out last week that ran a little hotter than people expected the 10 years back up to 4, 3. Remember, at the end of the year, I think it had gotten down to 3, 5. And then we had what I thought was a really provocative tweet at the end of the week from Larry Summers where he said the next move by the Fed could be higher. Now, why is this so provocative? Well, the market is betting for sure. The only debate about the soft landing has been when is the Fed going to cut, right? And so you have summers come out and say, hey, I think the next move could be higher. That would be a shock to the market. Was he being provocative or do you think there's real data that suggests that, that the soft landing is in a foregone conclusion? Well, listen, Larry was, was spot on, right, in 2022. Okay. I think last year he, he was a little bit too aggressive as to where he thought rates were going to have to go at the end of 22. I think he said maybe they could have to go to 6 or 7%. But I'm humble in the face that the future is unknown and unknowable. Like we don't know that's the truth of the matter. So as investors, we have to try to distribute this, these probabilities. And so if I go back and look at this, real rates, right? So real rates, this is the restrictiveness that we have in the economy. So this is effectively the interest rates. We have less the expected inflation rate in the future. They're as high as they've been since the fall of 2007. And the last time they were higher than that was in the summer, August of 2000. Okay, now what was the, what was going on August of 2000 and the fall of 2007? Well, the, the, the economy was on a heater and the Fed was trying to slow it down. Okay? So that's the level that the Fed currently has its foot on the brakes. And every month that inflation comes down, if it does okay, then the restrictiveness goes up. Right? So the Fed, if inflation is coming down, then the Fed does nothing and its foot goes harder on the brake. So that's why Powell has said we have to cut rates just to stay equally restrictive. So for Larry to be right, we would really have to see a reversal in inflation, which I don't think many people forecast or see. But I think the important takeaway is this as investors. I know, and you're already probably saying, God, how did Brad sidetrack me on macro? I don't, I don't want to talk about this. You know, I often think about that famous saying, if you don't do macro, macro does. You know, but when I think about, when I think about it in this moment, it's just to say stocks have run up a bunch at the start of this year, okay. The backdrop has gotten a little less predictable. There's now this tug of war that's going on. So I think we're going to have to see both of those things play out. And then of course this week, the monster that comes tomorrow, Bill, is Nvidia. In fact, you know, CNBC is screaming every day, whichever way Nvidia goes, so goes the market. Now I don't think it's quite like that, but one of the things that I was thinking about in regard to this is because we were making a bet that AI was for real, that training workloads were going to be large and that these inference workloads were going to kick in. And as investors we often take what we call this private equity approach to the public markets, which is let's get the big trends, the phase shifts, the super cycles. Right. I think about you had me over to Benchmark. This is years ago and you said Brad, will you come and talk about booking.com and the case you do at Columbia Business School in the old Graham and Dodd class that I, that I teach with Chris Begg, you know, on occasion. And the thing I try to teach the students in that class is why did all the analysts on Wall street miss booking.com right. Miss Priceline? Now remember Priceline was a billion dollar company in the public markets. Today it's 120,000,120, Bagger in the public markets. I mean there aren't many venture capitalists that ever get 120 bagger, let alone a public market investor. And the takeaway in the class is everybody in all the analysts on Wall street were so focused on how many hotels were they going to add in the quarter. Right. And there'd be a lot of volatility around the number of hotels added in the quarter. Nobody really took the time horizon to say in 5, 10, 15 years how much more the offline world is going to book their hotels online and how much bigger that's going to be. So often the short term trading they would get the long term conviction, right. But they would end up trading out of the position. So I look at Nvidia tomorrow and the honest to God truth is we have no edge on a quarter. We're on day to day trading of these things. I think we do believe that the amount, and we're going to talk about this later, the amount of compute that's going to have to be built in the world is way bigger than, than people, than consensus estimates, you know, currently forecast. But I think tomorrow it's going to. Be really interesting what could really move. I mean they're sold out, right. And their production's known. So it's just pricing that could be different, correct? Well, I think there's so every, every hedge fund, every long only person, they track all this data, right? So the co ops data, you know, the order books, the H100 data. And I think what people are seeing, and there's been some tweets about this, is that the lead Times on Nvidia H1 hundreds are going down. So what might you think? If the lead times are going down, you would say, oh, the demand must be going down or the supply must be going up. Catching up with demand. And you know, we've all been trained that every supply constraint is ultimately met with a glut. Right. So everybody's just the wall of worry around Nvidia is when does the glut come? We've pulled forward all this training. Demand is dark fiber, like in the year 2000. I think those things are not accurate. But of course I have no idea what this means as to tomorrow. So I think there are just tons of questions about AI chips, inference, how much of it's going to be going on. I know we're going to hit on a bunch of that today. So, you know, we stirred the pot last week a little bit or two weeks ago by questioning the consensus view on Google, which is that they're going to be a big AI winner. I think we called it the $2 trillion question. I tweeted about it, you know, Mark Suster chimed in and said, you know, I'll take the side that they're going to be an AI loser, you know, but why don't we dive in a little bit. You had this good idea, hey, let's look at these large cap tech companies through the lens. Are they winner, are they a loser from AI? Yeah. So let's, we may as well start. With Google, you know, and I wanted to back up a little bit and borrow a framework from one of my, one of my close friends and, and someone that I think a lot of people have listened to and learned from around investing, Mike Mobison. And years ago, shortly after I first met him, he was teaching a class at, at Columbia and they start, him and this guy Paul Johnson started talking about an acronym they titled Cap Competitive Advantage. Period. And what they would do is they would take a company's market cap and they'd look at the trends in the company and they would back into the number of years into the future that Wall street was telling you this company was going to have a competitive advantage. And by, by, by basically counting the number of years it would take in free cash flow to, to build into the market cap. Yeah. And what the point that he made is that, you know, different businesses have different amount of durability. And so, you know, Coca Cola might only have a 3% growth rate, but it might have a 40 or 50 pe. Because everyone is willing to bet that 75 years from now you'll still see Coca Cola on the shelves. Yeah, yeah, right. Whereas, you know, you, you look at a company that all of a sudden faces the innovator's dilemma or faces disruption, and this cap can close super fast and it has dramatic impacts on the market cap of the company. I remember when BlackBerry first got in trouble. The valuation just retrenched so aggressively that many people got fooled into thinking it was a value because it was trading at 10 times earnings. Yahoo. Same way. Yeah. And what was happening is the people in the know were saying this company's competitive advantage just became quickly. Undurable. Yes. I'm not sure undurable is the word, but you understand the point that I'm. Making oftentimes because we have a lot of high growth stocks in Silicon Valley and so they get assigned big multiples. Multiples are a byproduct of a couple things, how fast you're growing, because we're trying to forecast those free cash flows into the future. But also to the second point, the durability, because we have to assign a discount rate. What's the probability that we're actually going to be able to collect those annuities sometime in the future? And so the less confidence we have about the future, the higher the discount rate. And so even though you may have high growth, we have to discount it a lot. And Mike has gone on, I think, to talk about optionality, especially around tech companies. Sometimes you have platform position that increases the optionality. You're going to be able to move into other fields and therefore that would also be a positive. But other people have questioned why these tech companies have high multiples at all because they're so susceptible to tech disruption, in which case you could argue the other side. But anyway, the reason I, I thought this would be an interesting way to talk about some of the large companies and AI. We. I don't think there's a single person out here that is arguing that AI is not some kind of fundamental phase transition, Clay Christensen's disruptive wave or whatever. And in fact, I think the number one way you could probably commit Hari Kari as a, as a public company would be to, on your earnings call, say, we think AI is Full of shit like we don't want anything to do with it. And so everyone's forced to have an answer. And I think, you know, one, one example that's pretty obvious to everyone is Microsoft. I think it became very clear to a lot of investors when they learned about an LLM and what it was capable of and the fact it could help write code and then it could help you write a paper, you know, and it could help you with creative endeavors. People looked at the Microsoft portfolio of assets, especially where they make money around the Office suite. Right. And said, and, and the developer community where they also, you know, control a lot of the, the ides that are used to program. And they said, oh this is easy, Microsoft will be enhanced by this. And I, we should also add their, their adeptness at moving quickly with the OpenAI relationship and being they were, they were in front of this early. Absolutely. And so all three of those things, you go, oh this, they're in that winner. And lo and behold, you know, their stock went up and they had multiple expansion. Yeah, I mean I, I, I think that the first question we ask as investors is is this thing real? And what do we mean by real? What I mean by is the juice worth the squeeze? It costs me something to have AI if I'm a customer. Right. And is the productivity gains that I'm getting as a business worth it? Right. So you know, I was talking about Tesla. You know, start off the conversation. Well, if, if this model and this compute and all of this capability allows me to develop full self driving and to win the automotive market because of that, then of course the juice is worth the squeeze. I think if Copilot allows my engineers to be 30, 40, 50% more productive, then I'm replacing human beings with machines. Of course that's worth the squeeze. And so I would say that as we sit here in the early days. I would even say another way in the Microsoft case, if you're not using their tool and you're programming without it, you're falling behind. Right. And so it becomes, you know, a tool that you have to, have to remain competitive. Yeah. And so you know, to me, I, we really try to look at it through the lens of is this company like, if we look at their existing business, is their existing business enhanced or attacked because of AI and then what new business opportunities do they have? And, and if we go back to Google for a second here, because I think we, it's kind of this iconic study because the consensus view was that they were going to be a huge Winner in AI. And let, let, let's step back for a second here. 20 years ago, right, the idea that you were going to be able to ask any questions immediately, get information for free like Google gives us, right, was just beginning. And the gains to humanity caused by the, the revolution that Google really led around information discovery and how efficient and how quick they provided information discovery, it really just, it changed the world in every respect. It moved humanity forward. Back to Ridley's idea of ideas having sex, right? Like it just allowed us to have more ideas, collect more information, exchange more information. I asked the team to do a little analysis, like as investors, like what do we think the right multiple should be for, for Google? And like what, what are the things that are inputs into that? So if you think about this, Google does about 10 billion queries a day, right? So you know, a couple, a couple queries are more than a query for every human on the planet. And it has the most efficient system in the world for doing that. I think if you pull up this tweet from Vivek, it'll show that the number of queries that are asked of Google has slowed down a lot. Right? So they're growing at about 4% a year. Monetization is up a lot. 13% more ads on the page. We've talked about that. And so you have a 17% CAGR around search. And so the first thing that we just say is that the basic engagement, even before I had slowed down a lot because you're already at 10 billion queries a day. So next we took a crack at a chart that says how many of those queries are going to become chat GPT like queries, okay. And so the black line here is, is kind of the number of queries that are information retrieval queries on Google. And the blue line is the actual and the forecast by us for the chat GPT like equivalent queries that are going to occur. Now. What, where do we get that information? Well, first we know a little something about the number of queries on Chat GPT, right? And we know that OpenAI and Google are working on these search integrated experiences, I think they call it sge, where they're going to have answers like perplexity in line with search. I think that Microsoft is now doing this with the rebranded Copilot. So a lot of the information retrieval searches are going to be replaced with these chat GPT like server searches. And this is where it starts to get interesting because two things kick in, Bill Number one, it costs a hell of a lot more Right. To provide answers than it did to provide 10 blue links. So if you say like what's it cost to provide 10 blue links? It's about a third of a penny or less per query. Now what does it cost to do that for 750 tokens today. And of course this will go down over time, but it's 10x more, right. It's 4 cents per query. And then if you look at the refinement of queries that's really going on. So a lot of times, Bill, what they do is they, they'll Send back these 10 blue links and then they'll use that as their prompt. Right. To re query the engine. This could be up to 50x more expensive to serve an answer, a high quality answer to the consumer versus 10 blue links. So your cost goes up a lot. Well, what about revenue? So I asked the question on the other side. Well, we know that revenue goes down. Why? Because I'm not clicking on all these ads on the page. Right. And so revenue per search likely goes down. I think if you look at that in terms of what the gross margin is to Google, right, The cost of serving going up, the revenue coming down, I don't know. You may take a 95% margin today on a business where you have 99% share, your share likely goes down over time because you have people like ChatGPT you have to compete with. But worse yet, your margin on each of those queries goes down over time. I don't know what it nets out at. 50, 50%, 60%. Now mind you, for perplexity or copilot or meta, et cetera, that's a great business, a 50% margin business. And you know, it reminds me what we've all said so many times, Google's margin is their opportunity. So the problem for Google is they have to do this because their competitors are forcing them to do it. Okay, but it definitely is going to be a lower margin business and they're unlikely to have the 99% share. So everybody you know has texted and emailed me. Yeah, but they've got YouTube and they've got Gmail and they've got Gemini 1.5 and they've got all this stuff. And I stipulate all of that is true. Okay? But the business that today produces the vast majority of profits for the company. What percent you think? I mean, listen, I think that search and YouTube produce over a hundred and twenty, one hundred percent of the profits because they have a lot of money losing units in the business. But it's over 80% of the profits in the business. And so when you think about that now, listen, they've got great management, they can cut costs. There are lots of things they can do. I'm not saying this is going to occur overnight, but if you and I were talking with Clayton Christensen about the innovators dilemma and we were analyzing this business, this would really be case exhibit number one. Now, the irony of the innovator's dilemma, Bill, is most of the companies that face it, they know they face it. They know they face it. So the question is, why don't they do anything about. I think some don't, but in this case, I think there's no doubt. Right? Of course they know. Of course they know. Yeah. So the question is they're trying to thread the needle, right? Can we somehow modify this in a way where we continue to grow our quarterly earnings? Because just setting the platform on fire and retrenching in the public markets and doing all of that very, very. They are advantaged by one thing, that the searches that are going away first are Wikipedia, like searches that don't have much monetization. So it doesn't, it doesn't. The revenue doesn't come apart right away, even though, even though you might be losing search volume. And more importantly, like, people start getting addicted to the. The answer right away, right? Which is very different from 10 Blue Link. I think like the horse is out of the barn on answers, right? Like once consumers experience the magic of an answer, they're not going back to hunting and pecking for a roster for an athletic team through 10 blue links, like you're just going to use it. And all of this just reminded me lastly of somebody tweeted out a Grantham quote this week that I thought was pretty interesting. But it's this. If you pull out this tweet from, from Charlie, it says the S and P profit margins moved down to 10.6% Q4.23, the lowest since Q4 2020. And that is the quote from Grantham. I love. Profit margins are probably the most mean reverting series in finance. And if profit margins don't mean revert, then something has gone badly wrong with capitalism, right? I mean, what's happening here with Google? It's not that this is anomalous, right? When there are big pools of profits like exists in Google search capitalism has a way to redistribute. I think people had given up like, I agree, like Apple and Microsoft had given up 100% prior to this new. That's why that's why Satya says you, if you're in technology, if you run a company like Microsoft, all the money is made in the two to three years around a phase shift. You cannot miss a phase shift. If you miss it, then you miss all the value capture for the next decade. And I might argue with AI, it's going to be even bigger value capture and disruption and it's going to last longer than a decade. One other thing we don't know yet that I be interesting your thoughts on is what's the business model for this? Because right now the premium versions of Perplexity and Chat GBT have a dollar amount. They're a subscription. This kind of looks like the, the Netflix type situation. So is it subscription or is it, is it free? Do you want ads around your, your answers or not? Well, I mean, listen, remember the disruptors, they don't have to generate a lot of margin on this because they earn no money on it today. So what do they have to do? They have to cover their costs. Yeah. And these disruptors want to see Google dance, as Satya said. So the problem, I was surprised when he said that. I was too. But listen, listen, the fire in the belly is exactly what you need. I think Satya has founder level fire in the belly about this moment in time. And I think he has it not just because he wants to see the stock price go up. I think he has it because people like Satya, they're post money and what they care about right now is moving humanity forward and they understand that. They've worked their entire careers to get to this place where we go from computers acting like calculators that are modestly beneficial to now computers helping us answer and solve the most perplexing and fundamental questions that we face. And so I suspect that they're going to underprice this. If I were Perplexity, I would, I wouldn't have any ads in the thing. Right? No need to put ads in it. And I would attack and I would try to get share. Right. And so it would be surprising to me if we don't see meta AI and Microsoft and ByteDance and perplexity and all the others who are providing answer engines, ChatGPT coming at them below margin. Okay, now let's ask, let's answer the question that I'm talking about the shorter term while everybody is fighting to gain share, they'll price it so they cover their costs. Or maybe not. Maybe Microsoft's willing to eat it, you know, here for a while. And I continue like I as of right now and I've played with all of them on the consumer side I don't think anyone has a perplexity came out. It was a lot faster. That was pretty cool. But when I just look at the quality of the answers, I don't, I mean on different searches one might be better than the other but I don't see anything that so holistically notable. Like I remember when Google search came out like where I was, I remember trying it versus AltaVista and Yahoo and it was like you could tell like oh this is better. Right? And I don't see that. Right. I did have that feeling of ChatGPT versus a traditional Google search. Oh yeah. I mean you're saying among the answer. Now, now you have, you have four or five highly, highly backed, you know, companies competing in this consumer AI space and there I don't see anyone yet. Now I, as I said on our last pod, I think if you get this memory right, it could change. And since we did that, OpenAI published a, a release that says we're working on it, we're working on it. Here comes memory. But the promises were I think pretty thin relative to the bill. Explain to people again because I think this is so important. You and I are in agreement that this could be the next 10x moment with GPT like experiences for consumers. So just double click again on what your understanding is of memory and why you think your sensibilities are that it's so important. So I think there's two elements to this and one of them is a user expectation thing and then the second one is a technical observation. On the latter I, well let me, let me get to that in a second. But on the user expectation thing, you know it's funny I keep, I always go back to the movie her, which I thought was just incredible but like you I think want to be able to talk to this thing and have it remember everything that, that you ever told it. And if you had one that knew all of your emails, all of your contacts could remember your to do list could when you're about to meet someone that could bring up the last four times you met with them and the remind left yourself at that point in time. Like you're talking, you know, we talk about the, the programmers 30% productivity increase. This could be a human 30 or 40% like if you have this thing in your head that just remembers everything. So that's that. And by the way, and I said this last time, I think most people have just extrapolated AGI into infinity and think it's going to do all these things, but it's not doing it right now. And you know this. Cause you and I have been talking about this for a couple months now. If you talk to the people that are at the tops of these firms and you say, hey, why can't this thing remember everything I want? And they go, ooh, that's a hard problem. Exactly. And it turns out that just because of the way this thing works, it would literally have to retrain every night on each, every individual user. And training costs are super expensive right now. It's trained on the Internet, it's regurgitating the Internet. It's not trained training on everything in your database. Right. And so there are people, including OpenAI and all. I think everyone. This is another one of those things. I think they're all aware of this, but they don't know how to do it technically. And, and, and you know, I invite anyone to come on the show that thinks they know how to do it technically, if they'd like to correct us or whatever, I'd love. Or, or if there's a startup that thinks they know how, please come see us. And you, you and I've talked about this. I mean, and Listen, I think OpenAI opened the kimono a little bit. I think they're further out in front than they've revealed. But, you know, again, I come back to this idea that I'm really lucky out here. My, my assistant, Britt, she's been with me for 15 years. She knows me longitudinally, my likes, my dislikes, my family, everything about my kids, everything about hotels I've stayed at, rooms I want to stay in, etc. So my expectation of her is that she can take offload a lot of that because she has all that prior history. Right? And. But if every human had that. Exactly. You think about the productivity unlock for humans. If you give that for free to every human in their pocket. And I'm convinced it's going to happen. But one of the things I would suggest, I had a really interesting conversation with some friends about Apple. Okay. Because this is the giant, right? This is the thing in everybody's pocket. Nobody's talking about them, but they, they have so much information about me. Okay. They have my contact list, they have my emails, they have my texts, they have all these applications. And so one of the things, I'll just drop out there, I think a little provocative about what they may be doing because I've, I've read a bunch of stuff on Twitter about How they're building their large language model of their own. My sense is they're not doing that. Okay. My sense is in fact that if you think about it in the context of my assistant, right, so here's the metaphor I give to you. Would you rather have an assistant with the intelligence of like Einstein, but they have no access to the Internet and they don't know anything about your history, or would you like to have an assistant that's just above average intelligence, knows everything about you and they can use the Internet? Okay, you would choose that, right? You would choose the. And so think about what Apple's going to do, maybe more like a small language model, like really understand all the language, really understand everything about me, really understand how I interact with all these applications. And then when I have a deep problem I need to solve, they can sub agent it out, right? They can send me down the path of Chat GPT or send me down the path of Gemini, or send me to Meta AI for an answer engine if I want to go down that path. But I think that there's this layer on the top that's just a different architecture, a different way of thinking about this that's going to be more like my assistant Brit, that's just steering everybody in the right directions. I think Apple is superbly positioned to do this. But of course you don't want it to just. You also want to be able to tell it things that you just to remember this or mark this down or attach this to a note. And we've talked in the past about how an LLM could be a user interface disruption. And so you could imagine a small business starting with a CRM that is only voice, right? And you say this customer, this, you know, and you just talk to it and you want it to remember, right? But that has to be architected. Well, think about this like, you know, Brett Taylor's new business, Sierra. We're looking at a bunch of businesses in this space. Again, you and I are talking about it in the consumer landscape. Remember everything longitudinally about me, but what is a CRM? It's remembering everything longitudinally about your other. Your customers. Well, one thing I want to do just to wrap this up, because I think that you and I are analysts and you know, I think oftentimes in our business people talk about it. Is this company good or is this company bad? And I think one of the things you and I think about a lot is distribution of probabilities and is it reflected in valuation? So if you pull up this chart, we did which is the mang comparison. It just shows the growth rates and the multiples applied to Microsoft, Amazon, Nvidia and Google. And here all we did was take consensus numbers. So these are not altimeters numbers. Our numbers are higher for some and lower for others. But one of the things I just want to point out is at the top, this is the 23 through 25 expected growth rates. 14% for Microsoft, 12% for Amazon, 42% for Nvidia and 11% for Google. So Google's already expected out of those four to be growing at the slowest rate. But then what's interesting, if you come down here to the price to earnings ratio, right, you'll see that Google is trading at the lowest P E. Right, 21 times 24 and 20 or 18 times 20, 25 expected. So all the things that you and I just talked about, Bill, about growth rate and durability of free cash flows into the future, I would argue a lot of these are already discounted in the stock, right? People are already placing those bets. And so one might take the other side of that and say, yeah Brad, yeah Bill, I know all those things to be true. But they can cut a lot of costs and do a lot of things and that could cause the multiple to go up. But if you go down the line under that to the peg ratio, because this is one a lot of people want to ignore. On a price to earnings multiple, for example, Nvidia is a lot higher. But if you actually look at it on a peg ratio this year, it's a much less expensive company. If you look at on 25 peg ratios, it's just a little bit different. So there are two ways in which to look at future price to earnings multiples. One's growth adjusted, right? That tries to take growth out of the equation and just look at it in terms of strict valuation. So my, my big takeaway from this, Bill, is we're not here to pick on Google. We're just to say this is an important case study to watch about innovators dilemma. And it's clear to me that investors are already discounting it, that they have some of these headwinds coming. And I think there may be an opportunity. You know, I said the other day, if they manage to thread this needle, trust me, I'll climb on board that bus because I think they're tremendous costs. They can cut out that business. There's a lot of fitness they can drive into that business. And the real question is how are they going to drive down the cost of serving These inferences. And how are they going to monetize this in a way that, by the. Way, you know, it's funny because I think they have other assets. Like when you talked about Apple, you said they have the handset. Well, you know, Google controls the entire Android market, which is a big market. They have a competitor to Microsoft's Office suite now. They have historically not invested a lot in that. It's not a big driver of their revenue. They could. They could all of a sudden triple down. You know, they were ahead in type ahead. If you remember. Like my kids use those products and I was always on the Microsoft. And I can remember like it was finishing sentences for my kids. What was that? Right. That was inside of. Of Gmail. Yes. First. Yes. And so they have assets that, that they could bring to the bear. And I. And I. And I think, you know, everything you said about Apple is true. Like having the physical control of the physical device seems real to me. Like meta. Like the notion that my AI would live in my WhatsApp as a per person. I like that doesn't feel intellectually perfect to me. Like it being in the phone. Yes. Feels perfect to me. Like this thing's with me all the time. Let's talk about two things in that regard. So we talked about you. You talked about memory being a 10x chat GPT moment. So you said GPT was one of these 10x moments to you compared to blue links. If we got memory, that would probably feel 10x like, by the way, while. You'Re there, I have to say one thing that relates to valuation, ye. One thing that drives durability going back to our competitive advantage, period, is switching costs. If I start relying on one of these things as my memory and I don't have a way to pull that out and jump to something else, I'm stuck. Yes. Like, I am hooked. Lock stuck. Right. Which means we're multiple. Very, very positive for the person that gets there. So. So I think I'm looking for memory as a 10x moment. The other 10x moment I'm looking for here, Bill, is actions. Right. Going from answers to actions. And so let's talk about that for a second. Yeah. You know, this company, Rabbit's been making some waves. They have their version one out. Yeah, I saw. I think Tony Fadell tweeted the other day, can't wait to get his hands on one. There's a bunch of cool demos online. We've spent some time with the company and now the thing that they have or that they talk about is a huge differentiator, is what they call a large action model, not a large language model, large action model. And basically think of it like cursor control, Bill. So if I say, and in fact we did this demo upstairs when they were visiting, I said book an Uber going from but it was able to do it. It literally had trained on the behavior, cursor behavior of people using these apps and it was able to book that without any other intervention by me. So I took to doing some research and said could Apple do this? Because Apple knows exactly what pixel I'm using on the screen to hit a book button on booking.com or on Uber or whatever the case may be. Now remember Karpathy talked about this when he went to OpenAI the first time he worked on a project that he called World of Bits. And World of Bits, the iconic thing he tried to do there, and I think this was maybe five or six years ago, was to book a hotel. Could he get an AI to book a hotel? And he said at the time it was damn near impossible. He had to write all these very specific algorithms, had to try to figure out what every booking page look like. And he said recently on Lex Friedman, maybe a year ago, he said, I think if I tried to do it now using the general capabilities that exist today, it would be a lot easier. So I think that Apple's working on this. Clearly startups like Rabbit are looking on working on it. I think that is another 10x moment that's in front of us, which is we go from answers where I'm just asking it for information to actions. And once it can start booking my hotel booking, reserving my restaurant and then I just say same thing, do it again. Right? Because it has a little bit of memory about my prior action. Those are really powerful. There's a, there's an element of this that's just a fancier version of screen scraping, right? There's a, there's a, there's a hackiness. Yes to this, to this notion. And I've often said, you know, why in the world are we writing, in the self driving world are we writing, you know, millions and millions of line of code to infer the state of a, of a traffic light? Like why don't we just broadcast the state of the traffic light? And it would be, it would be three orders of magnitude less code. But, but, but guess what? I think we, we literally are going to bypass, I think if we had done that, that also would have been intensive, right? Because then we'd have had to Wire everything up to be coordinated. Well, here's where I think the world's going. We met with these robotics companies, we meet with Tesla, et cetera, imitation, learning. Okay? They're not even going to know what the stop sign is or the traffic light is or the dog in the street. They're not going to write C for every one of those specific incidents. They're literally going to watch the behavior of the five star human drivers for enough hours and they're going to imitate it. All right, but you're missing my point back on the, on the, on the Internet side, which is, is telling. Having the, having the AI like move my cursor around and click and fill out things is, is not the most, no, of course, efficient way to do this. You would, you would have API APIs, of course, with these different services and, and, and a way to interact and that's going to be a, an interesting evolution. And there's a number of startups working on this too, on different ways to try and drive action and to, you know, some of them will, will sit on top of browsers and do that, or some of them might try and sit on top of your phone. Of course Google and Apple will stop them from doing that. I totally agree with that. It's funny, I was asking our analysts, right? 10 billion queries a day on Google today I say, do the number of queries in the future go up or go down, right? And I had somebody, if I saw Arvin at Perplexity, said to me, well, the number of queries probably goes down because you don't have to ask it so many times, it'll just give you an answer. And I said, what about the positive reflexivity? Once I get the answer, I've got more questions, right? Like as long as it's fast and it's producing that information, I actually think actions and memory will unlock more interactions because it's so much more valuable to me. I'll start using it more and more for these future things and I don't. Know, it'd be interesting to see there, you know, for a while we've had the Alexis of the world or whatever, you know, do integrations, right? And so the, maybe the possibility exists that if I'm an Uber customer, an open table customer, that, that, that eventually I will tell them my favorite front end and they'll come to some agreement there so that they can pass my registration information through and that that all happens seamlessly. But there's a lot of work to do to make all that happen. Right. I mean, I, I think there's a lot of agent to agent interaction that will go on. An AI agent representing both of these parties. But what's interesting about the action model, you know, the hackiness that you talk about. Right. I imagine this will get solved by startups in some pretty hacky ways to begin, but then it will ultimately likely be solved at scale in more elegant ways, whether it's APIs or agent to agent interactions, et cetera. But we're starting to see real experimentation and I've had some of the early prototypes of actions actually coming to pass and that feels to me like the next two big breakthroughs are going to be this memory. And by the way, I said this last time and, and, and I, it's a subtle point, but I don't think Google, you know, it's another issue in the, in the disruption. I don't think Google has treated its partners well in the search ecosystem. And so there's a lot of, of angst there and a lot of mistrust. And so if OpenAI or Perplexity came along and said, would you integrate and pass tokens? They might say yes. I think they're going to be more reluctant to do that with Google. I mean, at a minimum, we know they would probably like more competitors in the game of sending them leads. Right. So I mean, I think just the fact that you're a smaller player, that you can be another source of competition and they're not so dependent on Google for upstream traffic is probably an advantage to you. Well, I know we're going to want to move to the topic of chips here in a second, but before we get there, we touched on Microsoft, we touched on Google, we touched on Apple just by way of comparison. And people have heard me talk about Meta a little bit in this regard. So again, the way we approach the analysis for all large cap tech, we said is their existing business get better or worse because of AI and then do their new business opportunities get bigger? Okay, so in the case of Meta, unlike Google, Google has this massive super profitable business that's under assault by answers and actions. In the case of Meta, we've seen their core business get better as a result of AI. Why? Because you're targeting videos now on reels, you're targeting. That happened pre alum. That was already happening. It was starting to happen. But the big difference really, I think between ByteDance and Meta was that Yeming at ByteDance adopted an approach around AI and GPUs before Meta did. And I think, I think Mark really made that transition about three years ago. You can see it in their capex spend. But the big question was obviously he had to spend the money before he got the results. And so investors like us were kind of holding our breath and we're saying, would this lead to better engagement? Well, now we know it's lead led to massively better engagement. And I'm not talking just on reels. This is on the core big blue Facebook product. This is on WhatsApp, this is on Instagram. So they have these big platforms that are benefiting from both more engagement and the targeting of ads. Remember this Stock was at 90 bucks and everybody said Facebook's dead because Apple attacked. Apple pushed through their changes that disabled their ability to really track people into what. And basically because of AI, they've been able to backfill that monetization completely. Nobody thought, no investors thought that was going to be the case 18 months ago. So their core business got a lot stronger. Now as we look ahead, think about the new business opportunities that are in front of them. And I'm just talking about the things that Mark's talked about on the call number one, they've got tens of millions of business customers that now they're literally creating these customer Service Agents for AI agents for every single WhatsApp business. Now we don't see that as much here in the US even though WhatsApp is the fastest growing messaging platform in the US but if you go to a place like India or Brazil, people are transacting some of the biggest AI engines. Right? AI bot companies are being built on WhatsApp as a platform in Brazil and in India, where they have tens of millions of customers already using them. So these have become platform companies that are enabling vertical and horizontal bots. And they're going to build their own. They're going to build it for celebrities. They're going to build shopping agents that assist me buying things on Instagram. You know, I always see all these things I like on Instagram, but it's a pain to actually buy the things on Instagram. The one click never got that easy. Now I think you're going to see shopping agents that assist in doing that. And then just think about this content creation bill, whether you're an advertiser, just think what we saw this week with Sora text to video. I mean, now think of this in the context of an advertiser trying to drive emotions. Or a creator. Or a creator, Right? So my sons are creators, creators on these platforms. This is going to unleash monster amounts of creation in the world at lower costs. And so all of that, I think benefits their core business. You have these new businesses that they get to move into that I just mentioned. Then of course, I thought another interesting thing from Morning Brew, I think the pod that Mark was on last week, he talked about the meta AI glasses that all my analysts have. Right. He said, you know, most people, they looked at Mark taking the video, reviewing the Vision Pro from his couch and they see, you know, that got a lot of clamor on Twitter. But the fact of the matter is, Mark said the way you ought to think of VR and AR really is as your desktop or your laptop. But the meta AI glasses he said think of as your phone. Right, Because I'm going to be able to text, I'm going to be able to call, I'm going to be able to listen to music, I'm going to be able to order my Uber, I'm going to be able to do all these things from those glasses and I don't have to pull out this rectangular thing or I keep it in my pocket or whatever. I think that's why you're seeing such incredible demand for those. And of course the form factors will change and it'll evolve over time, but that's an entirely new line of business. So this is a company that's spending $20 billion a year on these other businesses that haven't been generating a lot of return. And I think now the market's starting to assign some value to those businesses. But we, we should be fair, right? Like, cause YouTube benefits from those same dynamics that you talked about. And if you're talking about units of, of being the, the, the, the phone or the, like Apple and, and Google already have 100 huge install base like yes, what, four orders of magnitude to the number of Ray Ban glasses. Yeah, no, no, no, for sure. But I think the question is from where you are today, right? And so like I'll stipulate YouTube will be a better business in the future. Content targeting will be better, ad targeting will be better. Right. And as long as Google is able to backfill the, the core of search like we just discussed, then it's going to be worth more in the future. There's no doubt about it. And of course, in terms of just their basic research and development around AI, what they did with Gemini 1.5, et cetera, I mean like these, they have incredible talent and resources. The only liability is they have an incumbent business that is a monopoly business with monopoly profits. So, so that we can move on. Let's do a fast drive by. I'm going to do one on Apple and then you, and then you do Amazon. So get as a reminder to everybody, just our opinions, not investment advice. So for me, you know, Apple, you, you could argue they have the best asset in the world in this phone and it, and if you look at the user base of this compared to the Android user base, you know, it's just perfect. Right. And they, they have been doing Siri for a while and so you what, you connect those two things, you say shit like they put an LLM on top of this. They could get to all the data whether, I assure you, could give it permission to read your email. So you could literally get to all the data. So that's a massive positive. Now the negative is they haven't been known for Internet services. You look at Spotify relative to Amazon Music, Siri's kind of been, it's been terrible. Not evolving. Right. Like it's very much like it was the day it came out. Yeah. And so it would almost require a pivot of like, like Mark did on cost. You'd almost have to see Tim come out and say we're making a massive pivot like 180 degrees. We're going to be all in. Like, like we're putting our best engineers on this. And, and until that happens, I think it's a doubters camp. Yeah, well, I mean clearly it's been an underperformer this year. I mostly related to China market. Yeah, yeah, you have China market, but you have all these concerns in the market going just as to what's the durability of revenue going to be in the future. You clearly have, but they have the assets. Imagine if you took like five of the top AI people. I mean these companies and, and, and they were there. I'm like they were there the way Tony Fidel was there, you know, early on for the ipod. Like if you had that, you know. Listen, for the first time they have real challengers whether it's a humane, a rabbit, a meta, AI glasses, these other things. Right. Like I'm just saying the door has been cracked on the ecosystem. Siri has not evolved. Right. So they, they, I think they're the first to acknowledge that. I think they are going to try to disrupt themselves about that. I'm not sure whether we'll see a big breakthrough moment this year. I think we'll definitely see announcements this year about AI on the Edge, running on the phone and, and all these other things. And we'll start to see, they'll start to crack the door on this. To me, the big breakthrough on Apple is if they can run a 5, $10 billion parameter model on the phone on the edge without consuming all of my battery, which, you know, there's a lot of talk that they're going to be able to do that. They can maintain some memory about me and then they can show me the early part of actions on this device. It will unlock a huge new device cycle. Okay. And that's what drives this stuff. I was the one supposed to do you do. No, no. I'm, I'm going to ask you quick question. On the E commerce side of the business, does AI help or hurt Amazon? Yeah. Okay. And how much? Yeah, I think, I think on AI there, there are two. When I think about retail, E commerce, I think about it from two directions. First is Apple has been in the business of AI from a merchandising perspective just like Alibaba has been for a long time. Think about the largest retailer in the world, right? Think about the way Macy's used to work. There was somebody at the store who would say we're going to show black T shirts the front of the line at Amazon today. Nobody knows why they are targeting Brad Gerstner with certain things. It's a black box. Okay. So they're using it. But here's the thing. I, I, I think that is happening a bit to them on that front. And, and by the way, Andy Jassy is getting fit. They are tightening the screws on costs and all the other things. But look at a company like Temu, okay, that Pim Dodo in China owns that quickly became the largest advertiser on, on Facebook. Its E commerce sales are through the roof. Now what they're doing, I mean it's so incredibly clever. It's full stack AI so they don't even have inventory or merchandise. They literally go out and they, they collect data from customers about what they think they will want. They can assess how many of those things to build and they literally are building it for themselves. So they vertically integrated this AI E commerce business and then they're pushing it out the other end. And so I think there have been a lot of people in the US who have been dismissive but they've been shocked how big that business has come become in such a short period of time. We're starting to see this out of, out of tick tock as well where they're turning into an E commerce business. I think this opportunity sits in front of Meta as well. So I think there are some orthogonal challenges, but in terms of the core, I think their core continues to get better because of better targeting and, and AI reducing costs. Think about their customer care cost bill. We do have to move on, hit AWS as quickly as possible. Yeah. So I would, I would say aws. At the end of the day, these companies are in the business of renting AI services to end enterprises. Right. And as much as we talk about Azure and Microsoft running the table today, here's the truth. We've seen almost no share shift from AWS to Azure as a result of OpenAI. And if you would have asked me 12 months ago, I would have said jury's out as to whether or not that's going to happen. It didn't happen. Amazon responded quickly enough. And here's the other thing, you know, and Slootman's talk a lot about this term data gravity. Right. It turns out all my data's in aws. So long as they have a decent AI solution, I'm going to stick with them because I don't have to move anything. And I think they delivered that. I listened to a podcast and Jassy was talking about the fact that they have proprietary chips for both training and inference. And obviously as the AWS stack grew up, they had moved into networking chips, they moved into a lot of technologies people wouldn't have thought about Amazon owning or designing. Do you give them. And this would be a good transition, do you give them any chance of being competitive in it from an AI silicon perspective? So I think the right way to think about it is not will they build a better GPU than Nvidia? The right way to think about it is can they supplant part of the supercomputer? Right. The entire system? Are there pieces that they can pull out and plug in? Or workloads, specific workloads that they can serve with a lower cost infrastructure because they're doing hyper targeting silicon all the way to model. And I think the answer to that is yes. But I still think they'll be one of the largest buyers of Nvidia GPUs in the world because it doesn't replace that for a lot of really important work. One thing he also said that I think would be good for the listeners to hear and you know, I don't want to overstate, you know where Alexa is and we talked about Siri earlier, but he said that as Alexa got bigger, that the training costs are tiny compared to the inference cost. And he suggested, and maybe this is me interpolating that the inference market over time is going to be much more susceptible to, you know, things that are lower power, lower cost, all the, all the things that aren't just performance from a, from a silicon perspective. And I totally believe that to be true. And with that we can move to the biggest headlines of the week. We finally got here, which is this debate over the future of the compute build out needed to support AI. You know, to, to your earlier point about valuation. How unique is this revenue? How long does it last? And so we have a couple of charts just to bang or tweets to bang through here to kind of contextualize this. First, Nvidia stocks up a lot, but it's because the revenue and the profits have greatly exceeded expectations. So this chart just shows what their data center market share has grown to in the year. Right. The world is shifting toward AI as a compute infrastructure and they've benefited. One of the areas I think I tweeted about this, that I think has been greatly underestimated, this idea of sovereign demand. And I tweeted this week, you know, I think Jensen was over in the Middle east meeting with, with several of the GCC countries over there and I think what people still don't appreciate is they're probably dozens of sovereigns who are trying to get into the Nvidia order book and that they view it as one of their top three national priorities to build out AI capabilities. And I think the size you're talking about for some of these GCC countries is going to be competitors competitive with the hyperscalers itself. So in that context, right. When Sam Altman suggested and blew everybody's mind that he was going to raise $7 trillion to, you know, build chips. I don't know if he ever said, was inferred and repeated over and over and over again. So he threw out a big number. But I do think that we're talking trillions of dollars over the course of the next four to five years as we rebuild the world's compute infrastructure. And then finally Masa did not want to be left out and so he came out and said that he's going to raise a hundred billion dollars to build fabs and chips to compete with Nvidia as well. You've watched the semi industry for a long time. Okay, and, and more importantly, just the dynamics of supply and demand. So just step back for a second. Right. What do you make of all of this? Well, I have some cynicism but, but that comes naturally to me. The first thing I would say is they're, they're all talking about raising money from the exact same people. So if I were those people, I would just be a little careful because I think to a certain extent there's a, there's a smell of loose money or that, that's how I would interpret it because they're not, they're not saying they want to raise this money. Absolutely. They're saying they want to raise it from a very specific group in the Middle East. Yeah, so, so that's one thing too. I was struck when I read about sovereign server stacks. You know, there needs to be a reason. Right. It would have to be about, you know, wanting to have control over certain amounts of information. It could be proprietary information to your country, could be wanting to control how LLMs operate. Country servers typically depreciate a bit like fish, you know, and, and, and, and that's been true of DRAM and storage and all. You said fish. Right, Fish. Okay. They last a day, like. Yeah, well, I mean it's, it's, I'm being provocative, obviously, but people have talked about with that, with those, like you would, you wouldn't want to hoard any. Because what happens is, you know, the next generation comes along and it goes down quickly. So I, I would just, you know, there was a time at which Microsoft was trying to convince the world that we'd all need an NT server for every employee. And you know, when I heard that the first time, I was like trying to get like twist my head. So I don't know. I don't know if countries need server stacks. Maybe, like I said, it'd have to have those particular frames in mind. The second thing that just struck me, and this gets more to the Altman and the MASA quote, is the idea that we're just going to go compete with Nvidia is pretty radical. There are already people competing with Nvidia. AMD's competing with Nvidia. There are other people that have somewhat of a head start, like decades. Yeah. So you're just going to go do it. That's bold. It's not like chip design bins. Oh, oh yeah. And intel, obviously. But like, it's not like chip design bins to disruption or like software does like this is hard stuff. Yeah. And then some of them. And I once again, I don't know that there was an exact quote, but the idea that you're going to build a fab and compete, you're going to compete with TSMC and Nvidia at the same time. Like no chance. Yeah, like no chance. Because like let's say, let's say you got it. I mean we all know how the math works. But say you got a 20 chance of competing with either of them, right? Like then you're down to four like a pulling this off. And by the way, the time scale that you're going to need, like it, I mean just read. Well, we'll get into it in a minute because we'll talk about like what it means to have a competitive fab around the world. But TSMC is far, far ahead of the competition. And one of the reasons AMD has a higher market cap than intel today is specifically because they got out of the fab business and bet on tsmc. So I think, I think it's really important to tease out those two things. Right? There's chip design, right? And obviously Nvidia is already designing for two to three generations ahead. I mean the Series B is already taking orders in the order book, likely to launch in Q3 of this year and you know is order of magnitudes better than the H1 hundreds that are out there today. And then you're, they're already designing what comes after Blackwell. And so it's not as though they're standing still. And anybody who knows Jensen, he's an animal and that that company is, is playing for the future. And then if you look at TSMC and I shared with you a video, maybe just pull up a little bit about kind of the findings from that. But this is from the founder of TSMC and the CEO for decades, Morris, changing, talking about the competitive advantages and Bill, because this really gets to the fab, like why are all the world's fabs in Taiwan? Okay. And why aren't the fabs in Texas anymore with Texas Instruments? Or why aren't the fabs in other parts of the world and what does that mean for the future of this build out? And I think the implication of these, of these releases is that we're going to start building a bunch of fabs in the Middle East. I think we know we're trying to build fabs in Arizona. There's some talk about building fabs in Mexico, but maybe just let's deconstruct that one. What does it mean to build a fab outside of Taiwan to make next generation AI chips? You shared this link with me and I. It's a talk that Morris chang gave at MIT I think in November. Right. Very recently. He's over 90 and the first, it's like an hour long talk in the first 60% is a history lesson, but then the last 40%, I would encourage everyone to go watch, like everyone, including every politician in the United States of America. Because Morris makes the point that the reason Taiwan is competitive has to do with the labor model that exists there and the type of work people are willing to do and your ability to retain them. And he walks through his history of hiring in Texas and other parts of. The U.S. yeah, interestingly enough, he ran a fab plant for Texas Instruments in Texas. And he explains why Taiwan, like why Texas could never possibly compete with a fab plant in Taiwan. And, and he, even I, he, he admits that, that US was a manufacturing prowess in the 50s and 60s. But the, but, but the social requirements that we put on labor at that time are different than they are today. Yes. And so whether you look at TSMC and it turns out the same thing's true of a Foxconn factory in, in Mexico, you have people working longer hours, sometimes living in dormitories. And he mentions that in his talk and he says the country must more likely to disrupt Taiwan would be Vietnam or India. Yes. Not an advanced culture. And to think you're going to re onshore a fab and ignore Morris Chang is just kind of crazy to me. Right. And I look at the requirements once again that we put on companies around labor and say to myself, it's not going to happen here. And, and the people will quickly react to that and say, oh, you're in favor of, of forced labor or like super hard labor. But the people that are choosing that at that point in time are choosing a better life. Right. And to deny them that opportunity, like the, the, the, the individual that lives in Juarez that's commuting to this Foxconn plant is getting a better life. That's right. With even with his four nights a week in the dorm. And to deny him that and insist on our circa 2023 social norms on that country is unfair. Right. From my point of view. Right. And denies them their chance at disruption. So when you unpack, and we'll put the link to the video here, when you unpack that message, it's really that Taiwan thrived because these operators and technicians would spend their life working in the same fab on this. Getting, getting better and better at the same thing. And he Talked about a 12% churn rate, I think when he was at the fab in, in Texas. And he said the problem is the second a better job would come along, they would leave for a better job. That was, it was 12 during, during a recession. During 12 during a recession, implying that it was much higher. It was with the 25. When, when, when times were good, economy was good. And he said, you just can't run a fab plant with 25% churn among the operators. You, you produce really bad product. And I think the point is it's not just better life, it's also kind of these cultural norms. And so that's why he said, you know, in Vietnam and India they have cultural norms, he believes, that are more consistent with, with loyalty and staying with something longer. And on top of that, that it would be an improvement in the quality of life for the people who would take these jobs and therefore the incentive is there for them to stay in. Those positions either right nor wrong. Like I, you know, I'm not, not provocative, like. Yeah, it's provocative because it says that if America is really worried about the concentration in Taiwan, they should probably be trying to help build semiconductor plants in Mexico or Vietnam or that kind of thing versus bringing them here because the odds of operating them here in a competitive way, globally competitive way, are low. So I guess does that make you skeptical of the CHIPS Act? I mean, I see that intel is back in Washington looking for another $10 billion to subs the work that they're doing. I mean, I get the US national security concern, particularly considering that a hundred % or virtually 100% of these advanced chips are being manufactured in a place that has risk, has political risk associated with it. Bill, let me ask you this, by the way. I am, I am somewhat skeptical of CHIPS Act. And then the other thing I would say to you is like, China's probably in a really good place. Yeah, they're really smart. They have all the intellectual capability of being competitive and they probably still have this opportunity for them, you know, over time in terms of the willingness of certain part of their population to be willing to work in those types of situations. Yeah, I mean, I'll take probably the under on that. I think that the opportunity like now there is a global imperative to diversify the source of manufacturing. And I think Morris Chang was having this conversation at MIT recently because he understands the global imperative. I think you are going to see plants that get built in places like Vietnam and Japan. I think you are going to see them get built in India. You're probably going to see some attempts in the Middle East. Obviously we're trying to do some of this stuff here. I think from a United States interest, both in terms of wanting to maintain leadership in AI and wanting to diversify our political risk associated with Taiwan. It's not so important that everything is produced in the U.S. right. That shouldn't be our goal or objective for all the reasons that Morris Chang points out. But I do think it would be better if we had four or five places around the world that were load balancing the manufacturing of these. That's a fair point. And I think the whole re onshoring think argument conflates the national security interest with a, with a interest in American jobs and that kind of thing going back quickly to these new chip companies that are going to miraculously compete with Nvidia. I, I would, I would tell you if, if, and this is maybe, you know, an older venture capitalist talking and one who's watched different partners sit on the boards of, of startup semiconductor companies. It ain't easy, you know. And you know, the, the first silicon that comes back doesn't always work. Yeah. And you might be 50 million to first silicon, you might be a hundred million to first silicon. Right. You've got to get in line at TSMC. Right. How are you going to break that door down? How are you going to out compete beat Nvidia for TSMC's time? Right. Like how are you gonna get on that place? And it's hard. And by the way, once you do get working silicon, your yields are probably crappy. Yeah. Like that's what happens. Like this is, this is physical material science type stuff. It's not software. Right. And you're going up against again two companies that are running in pretty exceptional ways by exceptional founders. In the case of Jensen has been there for three decades. He's devoted his life to this. TSMC seemingly has similar types of leadership. But one of the things I wanted to pivot to on this bill because it begs the question why is Sam throwing out this really big number? Right. Why is Masa throwing out this really big number? And I think the answer, like one of the things I want to talk about is this, which is just what is the size of the market opportunity that we're talking about here? And so I have a slide. We had Jensen when he was in the Middle east, he mentioned, and the quote was, and this was just from February 24, he said there's about a trillion dollars worth of installed base of data centers around the world. And over the course of the next four to five years we'll have 2 trillion of data centers powering software around the world and it will all be accelerated compute. Okay. And so I asked my team to break that down a little Bit like what, you know, how does that look like per year, right. To get to this number. So of course I'm doing this from outside in. We take a swag at it and it pulls up this next line bar chart. So this is the AI data center build out. In blue is the new accelerated computer, right. In green is the replacement data center that we think will go to accelerated and then in gray is the replacement that's non accelerated compute. So this would be more like, you know, x86. And again I'm certain this is wrong specifically, but that's what we're in the business of doing, trying to build a forecast based upon folks who are providing this information. The line running through the center that starts at 55% and goes down to 26%, that is Nvidia's share of that global compute build out based on current consensus numbers for Nvidia, okay, so the consensus forecast that has the stock at $700 a share assumes, if you believe this TAM to be accurate, assumes that their share will go from 55% today to 26% in 2028. Now I think if you just step back and you say okay, do we think we're going to go from a trillion of data centers to 2 trillion of data centers? Just ask that at a high level. Okay, well you and I just spent an hour plus talking about how a 10 billion queries a day are likely to move from information retrieval right. To inference as we as humans expect to get answers rather than a card catalog. We talked about enterprises, whether they're doing their engineers in co generation or whether customer service centers or whether Tesla and full self driving or whether it's sovereigns who are taking on national security issues, you know, drone fleets, or whether it's proteins and life sciences or material sciences. There isn't going to be a single industry on the planet that's not employing accelerated computer in order to solve the problems of their enterprise. So if you said to me with that as the backdrop a year ago, I think the big question bill was is there going to be enough productivity gains in the world to justify this compute build out? Remember people thought oh, we're pulling forward all the demand for Nvidia. This is like dark fiber in 2000. We're going to be way oversupplied, we're going to have a glut. I think the evidence on the field is that that was wrong. I think the evidence on the field is that in fact, just like we talked about on the last pod, we tend to underestimate the size of these super cycles. Because when you have these phase shifts, everything changes. You have positive reflexivity in the world. More begets more because it's better, right? And so I think the bigger question when I look at this chart and what I push my team on, what I'm certain of, you know, when I the rumored pricing of H1 hundreds to B1 hundreds, is that B1 hundreds are going to cost even more than the H1 hundreds. And so I say to my team like these margins have to get competed down, right? But the feedback and something I think that's really important is that although the B100 is more expensive, it's so much more powerful, right? It's like this if, if you had an employee bill and you were paying him a hundred thousand dollars and I said hey, you ought to hire this other guy, he cost 200,000. You said well why would I hire him if he costs 200,000? I would say he does 10x the work of the guy who, who you pay a hundred thousand to. You would pay him $200,000 in a second, right? And I think that's why Nvidia today is getting those margins. In the future I expect that there's going to be more competition whether it comes from this custom chips that you're talking about, whether it's from other competitors like amd, whether it's from, you know, new startups that, from Masa or Sam, et cetera. But you and I just talked about the challenge to build a fab and the challenge to design those chips is non trivial and you know, the probabilities are somewhat low and so it's going to take time to get time. I mean if you're starting today like when would you have an impact? But one question I would have for you on this is, you know, if you're right about this, I wonder about TSMC's capacity, right? You know, and that is a limiter to this, right? So you're looking at the chart and saying how do we get to 2 trillion of replacement in new if TSMC is gated in their ability to produce these. Now Jensen gave this number, he's intimately familiar with TSMC and their ability to produce. So I said I, I think he has a sense of, in his head about what they can get done. I think that the other limit limiting factor we're going to run up against here pretty quick, it's not going to be capital, right? It may or may not be TSMC, but the power consumption. So even for the B100, the data center designs like you're talking about liquid cooling, custom designed data centers, they're going to consume massive amounts of power. And I think part of the reason you're hearing about this sovereign demand from the Middle East Bill, is they understand that their chief competitive advantage is low cost energy, right? And I don't think they're talking about building all of this just to service the needs of their country. I think they're smart enough to understand they're trying to equitize all their petrochemical wealth into technology wealth in the future. And if I was running one of those countries, I would look at this phase shift as an opportunity to become the supplier to the world of, of, of computer aided intelligence. Right? And if they can do that because they have lower cost energy and because they can recruit the likes of Sam Altman, they can recruit the likes of TSMC to their countries to set up shop there, to design chips there, it's not all that different than digging wells, right? Think about digging a well. You have to spend a lot of money, a lot of time, a lot of research. You're hoping you get your payback 5, 10, 15 years into the future. And so I think this is a rational decision by them to build out this capability. But to your point, it's a non zero and non trivial undertaking to try to get it done. Now if they do that, it's going to put them in competition with some of the hyperscalers, right? From core weave to AWS to others who are in the business of renting AI capabilities out. But I think it's good for the world because what we want to see is a lot of competition. We want to see the price of AI compute fall over time. That's going to lead to a lot more consumption. And because of the productivity gains from the end applications again, self driving cars or coming up with vaccines or solving complex problems or just allowing consumers to have answers instead of 10 blue links. We need the cost to come down on all this stuff. If you, and maybe this would be a good way to wrap, but if you, if you bring that, that attitude to the table, I mean it sounds like, and I don't want to put words in your mouth, but there's no, there's no reasonable end in sight from where you sit like on this wave. We're at the very beginning and it's going to go for a long. I said last week and I think we had a little video that went out and I said we are going to hit a zone of disillusionment. I don't know whether it's this quarter, maybe tomorrow with Nvidia when it starts, right. We're going to hit a zone of disillusionment where you have a mismatch between supply and demand. And then all the skeptics are going to say, I told you so. The Internet's a fad. AI is a fad. Mobile's a fad. Like it happens in every super cycle. We're going to use that as a buying opportunity because we are absolutely convinced that the Runway is longer and wider and the impact on humanity is going to be greater because the end applications are so compelling that are using AI to assist them in everything that they do. But that's really where the tug of war is in the world today, Bill. And that's what makes a market. Right? You're gonna have those people who are skeptics about that demand. That's what creates a wall of worry. You know. Why does Nvidia trade at 20 to 30 times earnings? Right. I would say because there's a lot of skeptics and there's a lot of worry about whether or not these free cash flow is durable into the future. Right. I bet you the worry's more on pricing than volume. Right. And by the way. And it's, it's unknowable. Right? Like I don't know. Nobody who follows this knows. So you have to assign some probability to that future outcome. But I think you're right. It is a good place to leave it. I wish you could be here. I know you're, you're, you're anchored down there in Texas. Speaking of Texas fabs. But this is fun to have you here in person. Good to see you. Like old times. And, and I think we're going to be talking and debating this for as long as we're doing this pod for sure. No doubt.", "segments": [{"speaker": "A", "start": 0.16, "end": 33.1, "text": "Would you rather have an assistant with the intelligence of like Einstein but they have no access to the Internet and they don't know anything about your history or would you like to have an assistant that's just above average intelligence, knows everything about you and they can use the Internet? Okay. You would choose that. Hey, great to have you here in person."}, {"speaker": "B", "start": 33.9, "end": 34.54, "text": "Good to be here."}, {"speaker": "A", "start": 34.54, "end": 43.26, "text": "I remember when you were right up this hill. Yeah, you guys were over here. So I, I had a couple thoughts this morning. First, I got to take a ride in full self driving 12."}, {"speaker": "B", "start": 43.42, "end": 44.22, "text": "How was that?"}, {"speaker": "A", "start": 44.3, "end": 68.23, "text": "It was mind boggling. I think this is going to be a bit of a chat GPT moment for full self driving. But what it really, it just reminded me of the magic of this moment. Tesla rebuilding their models for how they do self driving around, imitation learning and all this interesting stuff going on over there. Like, you know, I think they probably made more progress in the last 12 months than in the last seven years."}, {"speaker": "B", "start": 68.31, "end": 68.71, "text": "Wow."}, {"speaker": "A", "start": 68.71, "end": 79.91, "text": "In terms of, in terms of what's going on there and, and it's going to be rolled out here. It's already rolled out to I think 5,000 people. And so like people are going to start experiencing that. And I think we're having more and more of these moments."}, {"speaker": "B", "start": 79.99, "end": 80.39, "text": "Right."}, {"speaker": "A", "start": 80.55, "end": 83.67, "text": "Because this substrate we're going to talk a lot about today. AI."}, {"speaker": "B", "start": 84.03, "end": 84.43, "text": "Yeah."}, {"speaker": "A", "start": 84.59, "end": 124.86, "text": "And just to compute like what it unlocks. The second in prepping for this pod was how bad you make my head hurt. The. You know, I was thinking about this. You know what I love about this pod is like it's a forcing function. You know, you and I talk all the time, you're always challenging me, we're always comparing notes. But now with a little bit of structure around it, every couple weeks we have to think about some topics. Today we're going to talk a lot about think AI and compute and chips and its impact on big businesses. And honestly I liken it to an athlete, you know and they say in order to be the best I can possibly be, maybe Kobe, I want to practice against the best."}, {"speaker": "B", "start": 124.94, "end": 126.099, "text": "Oh no."}, {"speaker": "A", "start": 126.099, "end": 145.61, "text": "But it's like, listen, the reality is it's like running 10 miles a day to get ready for a big game. Like it's like if you're in this business and you're not exhausted with the analysis you're doing, the thinking you're doing, particularly at moments like these to try to gather this data and try to gather edge, then you're probably not going to end up on top of the heap."}, {"speaker": "B", "start": 146.09, "end": 163.13, "text": "I agree. And I think that having a topic or an idea that you want to fully flush out and be able to talk about, causes you to place a few phone calls, read a few PDFs, and before you know it, you actually realize you've learned something you didn't know five days earlier."}, {"speaker": "A", "start": 163.55, "end": 190.44, "text": "It's a, you know, I think the, the little, you know, pull the screen back a little bit. I mean, you and I have talked, you know, or interacted five, ten times a day over the course of last week on these topics. And then we turn over a rock and we find more data, more information, we share that with one another, it leads to another conversation. You know, and the combined networks allow us to ask a lot of the smartest people in the world the questions we need to be asking to try to figure out this moment. So it's been a lot of fun, but, but it does give me a."}, {"speaker": "B", "start": 190.44, "end": 202.48, "text": "Bit of a headache, hopefully a good one. So, so we remain, we remain kind of in earnings season and so what's happened in the past few weeks that you think's super important?"}, {"speaker": "A", "start": 203.44, "end": 294.01, "text": "Yeah, well, we have a lot of, we have a few stocks that have run a lot Meta Nvidia up 30, 40% even with the pullback that we had today. But the truth is the NASDAQ hasn't really moved that much. I mean, I think we're up 3 or 4% through today. If you look at the median stock, I think it's up about 1%. In fact, I think we have a chart here just on the dispersion that we see in the nasdaq. You know, and so remember last year was, was like this risk on moment, a mean reverting moment for all of technology. And this year we're, we're, we're really starting to see the winners and the losers. We have some software companies that reported after the bell tonight that are down a lot because they're not seeing the AI pull forward that maybe an Amazon or a Microsoft. So that's my first takeaway. My second takeaway is, you know, against these higher prices for some of these companies, you know, the backdrop looks a little bit more challenging. So we had a CPI print that came out last week that ran a little hotter than people expected the 10 years back up to 4, 3. Remember, at the end of the year, I think it had gotten down to 3, 5. And then we had what I thought was a really provocative tweet at the end of the week from Larry Summers where he said the next move by the Fed could be higher. Now, why is this so provocative? Well, the market is betting for sure. The only debate about the soft landing has been when is the Fed going to cut, right? And so you have summers come out and say, hey, I think the next move could be higher. That would be a shock to the market."}, {"speaker": "B", "start": 294.01, "end": 301.02, "text": "Was he being provocative or do you think there's real data that suggests that, that the soft landing is in a foregone conclusion?"}, {"speaker": "A", "start": 301.26, "end": 462.83, "text": "Well, listen, Larry was, was spot on, right, in 2022. Okay. I think last year he, he was a little bit too aggressive as to where he thought rates were going to have to go at the end of 22. I think he said maybe they could have to go to 6 or 7%. But I'm humble in the face that the future is unknown and unknowable. Like we don't know that's the truth of the matter. So as investors, we have to try to distribute this, these probabilities. And so if I go back and look at this, real rates, right? So real rates, this is the restrictiveness that we have in the economy. So this is effectively the interest rates. We have less the expected inflation rate in the future. They're as high as they've been since the fall of 2007. And the last time they were higher than that was in the summer, August of 2000. Okay, now what was the, what was going on August of 2000 and the fall of 2007? Well, the, the, the economy was on a heater and the Fed was trying to slow it down. Okay? So that's the level that the Fed currently has its foot on the brakes. And every month that inflation comes down, if it does okay, then the restrictiveness goes up. Right? So the Fed, if inflation is coming down, then the Fed does nothing and its foot goes harder on the brake. So that's why Powell has said we have to cut rates just to stay equally restrictive. So for Larry to be right, we would really have to see a reversal in inflation, which I don't think many people forecast or see. But I think the important takeaway is this as investors. I know, and you're already probably saying, God, how did Brad sidetrack me on macro? I don't, I don't want to talk about this. You know, I often think about that famous saying, if you don't do macro, macro does. You know, but when I think about, when I think about it in this moment, it's just to say stocks have run up a bunch at the start of this year, okay. The backdrop has gotten a little less predictable. There's now this tug of war that's going on. So I think we're going to have to see both of those things play out. And then of course this week, the monster that comes tomorrow, Bill, is Nvidia. In fact, you know, CNBC is screaming every day, whichever way Nvidia goes, so goes the market. Now I don't think it's quite like that, but one of the things that I was thinking about in regard to this is because we were making a bet that AI was for real, that training workloads were going to be large and that these inference workloads were going to kick in. And as investors we often take what we call this private equity approach to the public markets, which is let's get the big trends, the phase shifts, the super cycles."}, {"speaker": "C", "start": 462.83, "end": 463.15, "text": "Right."}, {"speaker": "A", "start": 463.55, "end": 509.33, "text": "I think about you had me over to Benchmark. This is years ago and you said Brad, will you come and talk about booking.com and the case you do at Columbia Business School in the old Graham and Dodd class that I, that I teach with Chris Begg, you know, on occasion. And the thing I try to teach the students in that class is why did all the analysts on Wall street miss booking.com right. Miss Priceline? Now remember Priceline was a billion dollar company in the public markets. Today it's 120,000,120, Bagger in the public markets. I mean there aren't many venture capitalists that ever get 120 bagger, let alone a public market investor. And the takeaway in the class is everybody in all the analysts on Wall street were so focused on how many hotels were they going to add in the quarter."}, {"speaker": "C", "start": 509.73, "end": 510.01, "text": "Right."}, {"speaker": "A", "start": 510.01, "end": 549.73, "text": "And there'd be a lot of volatility around the number of hotels added in the quarter. Nobody really took the time horizon to say in 5, 10, 15 years how much more the offline world is going to book their hotels online and how much bigger that's going to be. So often the short term trading they would get the long term conviction, right. But they would end up trading out of the position. So I look at Nvidia tomorrow and the honest to God truth is we have no edge on a quarter. We're on day to day trading of these things. I think we do believe that the amount, and we're going to talk about this later, the amount of compute that's going to have to be built in the world is way bigger than, than people, than consensus estimates, you know, currently forecast. But I think tomorrow it's going to."}, {"speaker": "B", "start": 549.73, "end": 557.57, "text": "Be really interesting what could really move. I mean they're sold out, right. And their production's known. So it's just pricing that could be different, correct?"}, {"speaker": "A", "start": 557.81, "end": 591.3, "text": "Well, I think there's so every, every hedge fund, every long only person, they track all this data, right? So the co ops data, you know, the order books, the H100 data. And I think what people are seeing, and there's been some tweets about this, is that the lead Times on Nvidia H1 hundreds are going down. So what might you think? If the lead times are going down, you would say, oh, the demand must be going down or the supply must be going up. Catching up with demand. And you know, we've all been trained that every supply constraint is ultimately met with a glut."}, {"speaker": "C", "start": 591.3, "end": 591.7, "text": "Right."}, {"speaker": "A", "start": 591.86, "end": 648.53, "text": "So everybody's just the wall of worry around Nvidia is when does the glut come? We've pulled forward all this training. Demand is dark fiber, like in the year 2000. I think those things are not accurate. But of course I have no idea what this means as to tomorrow. So I think there are just tons of questions about AI chips, inference, how much of it's going to be going on. I know we're going to hit on a bunch of that today. So, you know, we stirred the pot last week a little bit or two weeks ago by questioning the consensus view on Google, which is that they're going to be a big AI winner. I think we called it the $2 trillion question. I tweeted about it, you know, Mark Suster chimed in and said, you know, I'll take the side that they're going to be an AI loser, you know, but why don't we dive in a little bit. You had this good idea, hey, let's look at these large cap tech companies through the lens. Are they winner, are they a loser from AI?"}, {"speaker": "B", "start": 648.53, "end": 648.97, "text": "Yeah."}, {"speaker": "A", "start": 648.97, "end": 650.33, "text": "So let's, we may as well start."}, {"speaker": "B", "start": 650.33, "end": 702.55, "text": "With Google, you know, and I wanted to back up a little bit and borrow a framework from one of my, one of my close friends and, and someone that I think a lot of people have listened to and learned from around investing, Mike Mobison. And years ago, shortly after I first met him, he was teaching a class at, at Columbia and they start, him and this guy Paul Johnson started talking about an acronym they titled Cap Competitive Advantage. Period. And what they would do is they would take a company's market cap and they'd look at the trends in the company and they would back into the number of years into the future that Wall street was telling you this company was going to have a competitive advantage. And by, by, by basically counting the number of years it would take in free cash flow to, to build into the market cap."}, {"speaker": "A", "start": 702.55, "end": 702.95, "text": "Yeah."}, {"speaker": "B", "start": 703.19, "end": 724.13, "text": "And what the point that he made is that, you know, different businesses have different amount of durability. And so, you know, Coca Cola might only have a 3% growth rate, but it might have a 40 or 50 pe. Because everyone is willing to bet that 75 years from now you'll still see Coca Cola on the shelves."}, {"speaker": "C", "start": 724.13, "end": 725.01, "text": "Yeah, yeah, right."}, {"speaker": "B", "start": 725.01, "end": 753.439, "text": "Whereas, you know, you, you look at a company that all of a sudden faces the innovator's dilemma or faces disruption, and this cap can close super fast and it has dramatic impacts on the market cap of the company. I remember when BlackBerry first got in trouble. The valuation just retrenched so aggressively that many people got fooled into thinking it was a value because it was trading at 10 times earnings."}, {"speaker": "A", "start": 753.439, "end": 754.52, "text": "Yahoo. Same way."}, {"speaker": "B", "start": 754.6, "end": 763.76, "text": "Yeah. And what was happening is the people in the know were saying this company's competitive advantage just became quickly. Undurable."}, {"speaker": "C", "start": 763.76, "end": 764.12, "text": "Yes."}, {"speaker": "B", "start": 764.12, "end": 767.24, "text": "I'm not sure undurable is the word, but you understand the point that I'm."}, {"speaker": "A", "start": 767.24, "end": 795.76, "text": "Making oftentimes because we have a lot of high growth stocks in Silicon Valley and so they get assigned big multiples. Multiples are a byproduct of a couple things, how fast you're growing, because we're trying to forecast those free cash flows into the future. But also to the second point, the durability, because we have to assign a discount rate. What's the probability that we're actually going to be able to collect those annuities sometime in the future? And so the less confidence we have about the future, the higher the discount rate. And so even though you may have high growth, we have to discount it a lot."}, {"speaker": "B", "start": 795.76, "end": 826.3, "text": "And Mike has gone on, I think, to talk about optionality, especially around tech companies. Sometimes you have platform position that increases the optionality. You're going to be able to move into other fields and therefore that would also be a positive. But other people have questioned why these tech companies have high multiples at all because they're so susceptible to tech disruption, in which case you could argue the other side. But anyway, the reason I, I thought this would be an interesting way to talk about some of the large companies and AI."}, {"speaker": "A", "start": 826.74, "end": 826.98, "text": "We."}, {"speaker": "B", "start": 827.62, "end": 902.35, "text": "I don't think there's a single person out here that is arguing that AI is not some kind of fundamental phase transition, Clay Christensen's disruptive wave or whatever. And in fact, I think the number one way you could probably commit Hari Kari as a, as a public company would be to, on your earnings call, say, we think AI is Full of shit like we don't want anything to do with it. And so everyone's forced to have an answer. And I think, you know, one, one example that's pretty obvious to everyone is Microsoft. I think it became very clear to a lot of investors when they learned about an LLM and what it was capable of and the fact it could help write code and then it could help you write a paper, you know, and it could help you with creative endeavors. People looked at the Microsoft portfolio of assets, especially where they make money around the Office suite. Right. And said, and, and the developer community where they also, you know, control a lot of the, the ides that are used to program. And they said, oh this is easy, Microsoft will be enhanced by this. And I, we should also add their, their adeptness at moving quickly with the OpenAI relationship and being they were, they were in front of this early."}, {"speaker": "A", "start": 902.35, "end": 902.95, "text": "Absolutely."}, {"speaker": "B", "start": 902.95, "end": 910.74, "text": "And so all three of those things, you go, oh this, they're in that winner. And lo and behold, you know, their stock went up and they had multiple expansion."}, {"speaker": "A", "start": 911.14, "end": 924.1, "text": "Yeah, I mean I, I, I think that the first question we ask as investors is is this thing real? And what do we mean by real? What I mean by is the juice worth the squeeze? It costs me something to have AI if I'm a customer."}, {"speaker": "C", "start": 924.34, "end": 924.74, "text": "Right."}, {"speaker": "A", "start": 925.06, "end": 928.58, "text": "And is the productivity gains that I'm getting as a business worth it?"}, {"speaker": "C", "start": 928.58, "end": 928.9, "text": "Right."}, {"speaker": "A", "start": 928.9, "end": 954.14, "text": "So you know, I was talking about Tesla. You know, start off the conversation. Well, if, if this model and this compute and all of this capability allows me to develop full self driving and to win the automotive market because of that, then of course the juice is worth the squeeze. I think if Copilot allows my engineers to be 30, 40, 50% more productive, then I'm replacing human beings with machines. Of course that's worth the squeeze. And so I would say that as we sit here in the early days."}, {"speaker": "B", "start": 954.14, "end": 962.22, "text": "I would even say another way in the Microsoft case, if you're not using their tool and you're programming without it, you're falling behind."}, {"speaker": "C", "start": 962.38, "end": 962.78, "text": "Right."}, {"speaker": "B", "start": 962.86, "end": 967.86, "text": "And so it becomes, you know, a tool that you have to, have to remain competitive."}, {"speaker": "A", "start": 968.1, "end": 1062.32, "text": "Yeah. And so you know, to me, I, we really try to look at it through the lens of is this company like, if we look at their existing business, is their existing business enhanced or attacked because of AI and then what new business opportunities do they have? And, and if we go back to Google for a second here, because I think we, it's kind of this iconic study because the consensus view was that they were going to be a huge Winner in AI. And let, let, let's step back for a second here. 20 years ago, right, the idea that you were going to be able to ask any questions immediately, get information for free like Google gives us, right, was just beginning. And the gains to humanity caused by the, the revolution that Google really led around information discovery and how efficient and how quick they provided information discovery, it really just, it changed the world in every respect. It moved humanity forward. Back to Ridley's idea of ideas having sex, right? Like it just allowed us to have more ideas, collect more information, exchange more information. I asked the team to do a little analysis, like as investors, like what do we think the right multiple should be for, for Google? And like what, what are the things that are inputs into that? So if you think about this, Google does about 10 billion queries a day, right? So you know, a couple, a couple queries are more than a query for every human on the planet. And it has the most efficient system in the world for doing that. I think if you pull up this tweet from Vivek, it'll show that the number of queries that are asked of Google has slowed down a lot."}, {"speaker": "C", "start": 1062.32, "end": 1062.6, "text": "Right?"}, {"speaker": "A", "start": 1062.6, "end": 1177.7, "text": "So they're growing at about 4% a year. Monetization is up a lot. 13% more ads on the page. We've talked about that. And so you have a 17% CAGR around search. And so the first thing that we just say is that the basic engagement, even before I had slowed down a lot because you're already at 10 billion queries a day. So next we took a crack at a chart that says how many of those queries are going to become chat GPT like queries, okay. And so the black line here is, is kind of the number of queries that are information retrieval queries on Google. And the blue line is the actual and the forecast by us for the chat GPT like equivalent queries that are going to occur. Now. What, where do we get that information? Well, first we know a little something about the number of queries on Chat GPT, right? And we know that OpenAI and Google are working on these search integrated experiences, I think they call it sge, where they're going to have answers like perplexity in line with search. I think that Microsoft is now doing this with the rebranded Copilot. So a lot of the information retrieval searches are going to be replaced with these chat GPT like server searches. And this is where it starts to get interesting because two things kick in, Bill Number one, it costs a hell of a lot more Right. To provide answers than it did to provide 10 blue links. So if you say like what's it cost to provide 10 blue links? It's about a third of a penny or less per query. Now what does it cost to do that for 750 tokens today. And of course this will go down over time, but it's 10x more, right. It's 4 cents per query. And then if you look at the refinement of queries that's really going on. So a lot of times, Bill, what they do is they, they'll Send back these 10 blue links and then they'll use that as their prompt."}, {"speaker": "C", "start": 1177.94, "end": 1178.3, "text": "Right."}, {"speaker": "A", "start": 1178.3, "end": 1197.48, "text": "To re query the engine. This could be up to 50x more expensive to serve an answer, a high quality answer to the consumer versus 10 blue links. So your cost goes up a lot. Well, what about revenue? So I asked the question on the other side. Well, we know that revenue goes down. Why? Because I'm not clicking on all these ads on the page."}, {"speaker": "C", "start": 1197.8, "end": 1198.2, "text": "Right."}, {"speaker": "A", "start": 1198.2, "end": 1269.78, "text": "And so revenue per search likely goes down. I think if you look at that in terms of what the gross margin is to Google, right, The cost of serving going up, the revenue coming down, I don't know. You may take a 95% margin today on a business where you have 99% share, your share likely goes down over time because you have people like ChatGPT you have to compete with. But worse yet, your margin on each of those queries goes down over time. I don't know what it nets out at. 50, 50%, 60%. Now mind you, for perplexity or copilot or meta, et cetera, that's a great business, a 50% margin business. And you know, it reminds me what we've all said so many times, Google's margin is their opportunity. So the problem for Google is they have to do this because their competitors are forcing them to do it. Okay, but it definitely is going to be a lower margin business and they're unlikely to have the 99% share. So everybody you know has texted and emailed me. Yeah, but they've got YouTube and they've got Gmail and they've got Gemini 1.5 and they've got all this stuff. And I stipulate all of that is true. Okay? But the business that today produces the vast majority of profits for the company."}, {"speaker": "B", "start": 1270.18, "end": 1271.22, "text": "What percent you think?"}, {"speaker": "A", "start": 1271.22, "end": 1309.26, "text": "I mean, listen, I think that search and YouTube produce over a hundred and twenty, one hundred percent of the profits because they have a lot of money losing units in the business. But it's over 80% of the profits in the business. And so when you think about that now, listen, they've got great management, they can cut costs. There are lots of things they can do. I'm not saying this is going to occur overnight, but if you and I were talking with Clayton Christensen about the innovators dilemma and we were analyzing this business, this would really be case exhibit number one. Now, the irony of the innovator's dilemma, Bill, is most of the companies that face it, they know they face it. They know they face it. So the question is, why don't they do anything about."}, {"speaker": "B", "start": 1309.66, "end": 1314.42, "text": "I think some don't, but in this case, I think there's no doubt."}, {"speaker": "A", "start": 1314.42, "end": 1316.5, "text": "Right? Of course they know. Of course they know."}, {"speaker": "B", "start": 1316.5, "end": 1316.86, "text": "Yeah."}, {"speaker": "A", "start": 1316.86, "end": 1330.38, "text": "So the question is they're trying to thread the needle, right? Can we somehow modify this in a way where we continue to grow our quarterly earnings? Because just setting the platform on fire and retrenching in the public markets and doing all of that very, very."}, {"speaker": "B", "start": 1330.46, "end": 1354.94, "text": "They are advantaged by one thing, that the searches that are going away first are Wikipedia, like searches that don't have much monetization. So it doesn't, it doesn't. The revenue doesn't come apart right away, even though, even though you might be losing search volume. And more importantly, like, people start getting addicted to the. The answer right away, right? Which is very different from 10 Blue Link."}, {"speaker": "A", "start": 1354.94, "end": 1409.0, "text": "I think like the horse is out of the barn on answers, right? Like once consumers experience the magic of an answer, they're not going back to hunting and pecking for a roster for an athletic team through 10 blue links, like you're just going to use it. And all of this just reminded me lastly of somebody tweeted out a Grantham quote this week that I thought was pretty interesting. But it's this. If you pull out this tweet from, from Charlie, it says the S and P profit margins moved down to 10.6% Q4.23, the lowest since Q4 2020. And that is the quote from Grantham. I love. Profit margins are probably the most mean reverting series in finance. And if profit margins don't mean revert, then something has gone badly wrong with capitalism, right? I mean, what's happening here with Google? It's not that this is anomalous, right? When there are big pools of profits like exists in Google search capitalism has a way to redistribute."}, {"speaker": "B", "start": 1409.08, "end": 1415.89, "text": "I think people had given up like, I agree, like Apple and Microsoft had given up 100% prior to this new."}, {"speaker": "A", "start": 1415.89, "end": 1436.97, "text": "That's why that's why Satya says you, if you're in technology, if you run a company like Microsoft, all the money is made in the two to three years around a phase shift. You cannot miss a phase shift. If you miss it, then you miss all the value capture for the next decade. And I might argue with AI, it's going to be even bigger value capture and disruption and it's going to last longer than a decade."}, {"speaker": "B", "start": 1436.97, "end": 1461.91, "text": "One other thing we don't know yet that I be interesting your thoughts on is what's the business model for this? Because right now the premium versions of Perplexity and Chat GBT have a dollar amount. They're a subscription. This kind of looks like the, the Netflix type situation. So is it subscription or is it, is it free? Do you want ads around your, your answers or not?"}, {"speaker": "A", "start": 1462.07, "end": 1474.28, "text": "Well, I mean, listen, remember the disruptors, they don't have to generate a lot of margin on this because they earn no money on it today. So what do they have to do? They have to cover their costs."}, {"speaker": "B", "start": 1474.28, "end": 1474.64, "text": "Yeah."}, {"speaker": "A", "start": 1474.64, "end": 1479.84, "text": "And these disruptors want to see Google dance, as Satya said."}, {"speaker": "B", "start": 1480.0, "end": 1481.84, "text": "So the problem, I was surprised when he said that."}, {"speaker": "A", "start": 1482.16, "end": 1524.98, "text": "I was too. But listen, listen, the fire in the belly is exactly what you need. I think Satya has founder level fire in the belly about this moment in time. And I think he has it not just because he wants to see the stock price go up. I think he has it because people like Satya, they're post money and what they care about right now is moving humanity forward and they understand that. They've worked their entire careers to get to this place where we go from computers acting like calculators that are modestly beneficial to now computers helping us answer and solve the most perplexing and fundamental questions that we face. And so I suspect that they're going to underprice this. If I were Perplexity, I would, I wouldn't have any ads in the thing."}, {"speaker": "C", "start": 1525.06, "end": 1525.46, "text": "Right?"}, {"speaker": "A", "start": 1525.78, "end": 1529.38, "text": "No need to put ads in it. And I would attack and I would try to get share."}, {"speaker": "C", "start": 1529.86, "end": 1530.26, "text": "Right."}, {"speaker": "A", "start": 1530.34, "end": 1556.92, "text": "And so it would be surprising to me if we don't see meta AI and Microsoft and ByteDance and perplexity and all the others who are providing answer engines, ChatGPT coming at them below margin. Okay, now let's ask, let's answer the question that I'm talking about the shorter term while everybody is fighting to gain share, they'll price it so they cover their costs. Or maybe not. Maybe Microsoft's willing to eat it, you know, here for a while."}, {"speaker": "B", "start": 1556.92, "end": 1590.84, "text": "And I continue like I as of right now and I've played with all of them on the consumer side I don't think anyone has a perplexity came out. It was a lot faster. That was pretty cool. But when I just look at the quality of the answers, I don't, I mean on different searches one might be better than the other but I don't see anything that so holistically notable. Like I remember when Google search came out like where I was, I remember trying it versus AltaVista and Yahoo and it was like you could tell like oh this is better."}, {"speaker": "C", "start": 1590.92, "end": 1591.28, "text": "Right?"}, {"speaker": "B", "start": 1591.28, "end": 1592.68, "text": "And I don't see that. Right."}, {"speaker": "A", "start": 1593.16, "end": 1597.4, "text": "I did have that feeling of ChatGPT versus a traditional Google search."}, {"speaker": "B", "start": 1597.58, "end": 1598.06, "text": "Oh yeah."}, {"speaker": "A", "start": 1598.14, "end": 1600.14, "text": "I mean you're saying among the answer."}, {"speaker": "B", "start": 1600.14, "end": 1626.8, "text": "Now, now you have, you have four or five highly, highly backed, you know, companies competing in this consumer AI space and there I don't see anyone yet. Now I, as I said on our last pod, I think if you get this memory right, it could change. And since we did that, OpenAI published a, a release that says we're working on it, we're working on it. Here comes memory. But the promises were I think pretty thin relative to the bill."}, {"speaker": "A", "start": 1626.8, "end": 1643.52, "text": "Explain to people again because I think this is so important. You and I are in agreement that this could be the next 10x moment with GPT like experiences for consumers. So just double click again on what your understanding is of memory and why you think your sensibilities are that it's so important."}, {"speaker": "B", "start": 1643.6, "end": 1745.59, "text": "So I think there's two elements to this and one of them is a user expectation thing and then the second one is a technical observation. On the latter I, well let me, let me get to that in a second. But on the user expectation thing, you know it's funny I keep, I always go back to the movie her, which I thought was just incredible but like you I think want to be able to talk to this thing and have it remember everything that, that you ever told it. And if you had one that knew all of your emails, all of your contacts could remember your to do list could when you're about to meet someone that could bring up the last four times you met with them and the remind left yourself at that point in time. Like you're talking, you know, we talk about the, the programmers 30% productivity increase. This could be a human 30 or 40% like if you have this thing in your head that just remembers everything. So that's that. And by the way, and I said this last time, I think most people have just extrapolated AGI into infinity and think it's going to do all these things, but it's not doing it right now. And you know this. Cause you and I have been talking about this for a couple months now. If you talk to the people that are at the tops of these firms and you say, hey, why can't this thing remember everything I want? And they go, ooh, that's a hard problem. Exactly. And it turns out that just because of the way this thing works, it would literally have to retrain every night on each, every individual user. And training costs are super expensive right now. It's trained on the Internet, it's regurgitating the Internet. It's not trained training on everything in your database."}, {"speaker": "C", "start": 1745.59, "end": 1745.87, "text": "Right."}, {"speaker": "B", "start": 1745.87, "end": 1768.55, "text": "And so there are people, including OpenAI and all. I think everyone. This is another one of those things. I think they're all aware of this, but they don't know how to do it technically. And, and, and you know, I invite anyone to come on the show that thinks they know how to do it technically, if they'd like to correct us or whatever, I'd love. Or, or if there's a startup that thinks they know how, please come see us."}, {"speaker": "A", "start": 1769.91, "end": 1804.51, "text": "And you, you and I've talked about this. I mean, and Listen, I think OpenAI opened the kimono a little bit. I think they're further out in front than they've revealed. But, you know, again, I come back to this idea that I'm really lucky out here. My, my assistant, Britt, she's been with me for 15 years. She knows me longitudinally, my likes, my dislikes, my family, everything about my kids, everything about hotels I've stayed at, rooms I want to stay in, etc. So my expectation of her is that she can take offload a lot of that because she has all that prior history."}, {"speaker": "C", "start": 1804.67, "end": 1805.07, "text": "Right?"}, {"speaker": "A", "start": 1805.63, "end": 1806.03, "text": "And."}, {"speaker": "B", "start": 1807.07, "end": 1808.75, "text": "But if every human had that."}, {"speaker": "A", "start": 1808.83, "end": 1920.9, "text": "Exactly. You think about the productivity unlock for humans. If you give that for free to every human in their pocket. And I'm convinced it's going to happen. But one of the things I would suggest, I had a really interesting conversation with some friends about Apple. Okay. Because this is the giant, right? This is the thing in everybody's pocket. Nobody's talking about them, but they, they have so much information about me. Okay. They have my contact list, they have my emails, they have my texts, they have all these applications. And so one of the things, I'll just drop out there, I think a little provocative about what they may be doing because I've, I've read a bunch of stuff on Twitter about How they're building their large language model of their own. My sense is they're not doing that. Okay. My sense is in fact that if you think about it in the context of my assistant, right, so here's the metaphor I give to you. Would you rather have an assistant with the intelligence of like Einstein, but they have no access to the Internet and they don't know anything about your history, or would you like to have an assistant that's just above average intelligence, knows everything about you and they can use the Internet? Okay, you would choose that, right? You would choose the. And so think about what Apple's going to do, maybe more like a small language model, like really understand all the language, really understand everything about me, really understand how I interact with all these applications. And then when I have a deep problem I need to solve, they can sub agent it out, right? They can send me down the path of Chat GPT or send me down the path of Gemini, or send me to Meta AI for an answer engine if I want to go down that path. But I think that there's this layer on the top that's just a different architecture, a different way of thinking about this that's going to be more like my assistant Brit, that's just steering everybody in the right directions. I think Apple is superbly positioned to do this."}, {"speaker": "B", "start": 1920.9, "end": 1952.29, "text": "But of course you don't want it to just. You also want to be able to tell it things that you just to remember this or mark this down or attach this to a note. And we've talked in the past about how an LLM could be a user interface disruption. And so you could imagine a small business starting with a CRM that is only voice, right? And you say this customer, this, you know, and you just talk to it and you want it to remember, right? But that has to be architected."}, {"speaker": "A", "start": 1952.29, "end": 2126.51, "text": "Well, think about this like, you know, Brett Taylor's new business, Sierra. We're looking at a bunch of businesses in this space. Again, you and I are talking about it in the consumer landscape. Remember everything longitudinally about me, but what is a CRM? It's remembering everything longitudinally about your other. Your customers. Well, one thing I want to do just to wrap this up, because I think that you and I are analysts and you know, I think oftentimes in our business people talk about it. Is this company good or is this company bad? And I think one of the things you and I think about a lot is distribution of probabilities and is it reflected in valuation? So if you pull up this chart, we did which is the mang comparison. It just shows the growth rates and the multiples applied to Microsoft, Amazon, Nvidia and Google. And here all we did was take consensus numbers. So these are not altimeters numbers. Our numbers are higher for some and lower for others. But one of the things I just want to point out is at the top, this is the 23 through 25 expected growth rates. 14% for Microsoft, 12% for Amazon, 42% for Nvidia and 11% for Google. So Google's already expected out of those four to be growing at the slowest rate. But then what's interesting, if you come down here to the price to earnings ratio, right, you'll see that Google is trading at the lowest P E. Right, 21 times 24 and 20 or 18 times 20, 25 expected. So all the things that you and I just talked about, Bill, about growth rate and durability of free cash flows into the future, I would argue a lot of these are already discounted in the stock, right? People are already placing those bets. And so one might take the other side of that and say, yeah Brad, yeah Bill, I know all those things to be true. But they can cut a lot of costs and do a lot of things and that could cause the multiple to go up. But if you go down the line under that to the peg ratio, because this is one a lot of people want to ignore. On a price to earnings multiple, for example, Nvidia is a lot higher. But if you actually look at it on a peg ratio this year, it's a much less expensive company. If you look at on 25 peg ratios, it's just a little bit different. So there are two ways in which to look at future price to earnings multiples. One's growth adjusted, right? That tries to take growth out of the equation and just look at it in terms of strict valuation. So my, my big takeaway from this, Bill, is we're not here to pick on Google. We're just to say this is an important case study to watch about innovators dilemma. And it's clear to me that investors are already discounting it, that they have some of these headwinds coming. And I think there may be an opportunity. You know, I said the other day, if they manage to thread this needle, trust me, I'll climb on board that bus because I think they're tremendous costs. They can cut out that business. There's a lot of fitness they can drive into that business. And the real question is how are they going to drive down the cost of serving These inferences. And how are they going to monetize this in a way that, by the."}, {"speaker": "B", "start": 2126.51, "end": 2164.88, "text": "Way, you know, it's funny because I think they have other assets. Like when you talked about Apple, you said they have the handset. Well, you know, Google controls the entire Android market, which is a big market. They have a competitor to Microsoft's Office suite now. They have historically not invested a lot in that. It's not a big driver of their revenue. They could. They could all of a sudden triple down. You know, they were ahead in type ahead. If you remember. Like my kids use those products and I was always on the Microsoft. And I can remember like it was finishing sentences for my kids. What was that?"}, {"speaker": "C", "start": 2164.88, "end": 2165.24, "text": "Right."}, {"speaker": "B", "start": 2165.24, "end": 2167.24, "text": "That was inside of. Of Gmail."}, {"speaker": "C", "start": 2167.24, "end": 2167.6, "text": "Yes."}, {"speaker": "B", "start": 2167.6, "end": 2167.96, "text": "First."}, {"speaker": "C", "start": 2167.96, "end": 2168.4, "text": "Yes."}, {"speaker": "B", "start": 2168.4, "end": 2195.25, "text": "And so they have assets that, that they could bring to the bear. And I. And I. And I think, you know, everything you said about Apple is true. Like having the physical control of the physical device seems real to me. Like meta. Like the notion that my AI would live in my WhatsApp as a per person. I like that doesn't feel intellectually perfect to me. Like it being in the phone."}, {"speaker": "C", "start": 2195.25, "end": 2195.73, "text": "Yes."}, {"speaker": "B", "start": 2195.73, "end": 2199.49, "text": "Feels perfect to me. Like this thing's with me all the time."}, {"speaker": "A", "start": 2199.65, "end": 2215.77, "text": "Let's talk about two things in that regard. So we talked about you. You talked about memory being a 10x chat GPT moment. So you said GPT was one of these 10x moments to you compared to blue links. If we got memory, that would probably feel 10x like, by the way, while."}, {"speaker": "B", "start": 2215.77, "end": 2236.21, "text": "You'Re there, I have to say one thing that relates to valuation, ye. One thing that drives durability going back to our competitive advantage, period, is switching costs. If I start relying on one of these things as my memory and I don't have a way to pull that out and jump to something else, I'm stuck."}, {"speaker": "A", "start": 2236.21, "end": 2236.61, "text": "Yes."}, {"speaker": "B", "start": 2236.61, "end": 2238.61, "text": "Like, I am hooked. Lock stuck."}, {"speaker": "C", "start": 2238.61, "end": 2238.97, "text": "Right."}, {"speaker": "A", "start": 2239.05, "end": 2240.29, "text": "Which means we're multiple."}, {"speaker": "B", "start": 2240.29, "end": 2242.57, "text": "Very, very positive for the person that gets there."}, {"speaker": "A", "start": 2242.57, "end": 2249.5, "text": "So. So I think I'm looking for memory as a 10x moment. The other 10x moment I'm looking for here, Bill, is actions."}, {"speaker": "C", "start": 2249.74, "end": 2250.14, "text": "Right."}, {"speaker": "A", "start": 2250.22, "end": 2375.8, "text": "Going from answers to actions. And so let's talk about that for a second. Yeah. You know, this company, Rabbit's been making some waves. They have their version one out. Yeah, I saw. I think Tony Fadell tweeted the other day, can't wait to get his hands on one. There's a bunch of cool demos online. We've spent some time with the company and now the thing that they have or that they talk about is a huge differentiator, is what they call a large action model, not a large language model, large action model. And basically think of it like cursor control, Bill. So if I say, and in fact we did this demo upstairs when they were visiting, I said book an Uber going from but it was able to do it. It literally had trained on the behavior, cursor behavior of people using these apps and it was able to book that without any other intervention by me. So I took to doing some research and said could Apple do this? Because Apple knows exactly what pixel I'm using on the screen to hit a book button on booking.com or on Uber or whatever the case may be. Now remember Karpathy talked about this when he went to OpenAI the first time he worked on a project that he called World of Bits. And World of Bits, the iconic thing he tried to do there, and I think this was maybe five or six years ago, was to book a hotel. Could he get an AI to book a hotel? And he said at the time it was damn near impossible. He had to write all these very specific algorithms, had to try to figure out what every booking page look like. And he said recently on Lex Friedman, maybe a year ago, he said, I think if I tried to do it now using the general capabilities that exist today, it would be a lot easier. So I think that Apple's working on this. Clearly startups like Rabbit are looking on working on it. I think that is another 10x moment that's in front of us, which is we go from answers where I'm just asking it for information to actions. And once it can start booking my hotel booking, reserving my restaurant and then I just say same thing, do it again. Right? Because it has a little bit of memory about my prior action. Those are really powerful."}, {"speaker": "B", "start": 2375.96, "end": 2404.76, "text": "There's a, there's an element of this that's just a fancier version of screen scraping, right? There's a, there's a, there's a hackiness. Yes to this, to this notion. And I've often said, you know, why in the world are we writing, in the self driving world are we writing, you know, millions and millions of line of code to infer the state of a, of a traffic light? Like why don't we just broadcast the state of the traffic light? And it would be, it would be three orders of magnitude less code."}, {"speaker": "A", "start": 2404.76, "end": 2438.81, "text": "But, but, but guess what? I think we, we literally are going to bypass, I think if we had done that, that also would have been intensive, right? Because then we'd have had to Wire everything up to be coordinated. Well, here's where I think the world's going. We met with these robotics companies, we meet with Tesla, et cetera, imitation, learning. Okay? They're not even going to know what the stop sign is or the traffic light is or the dog in the street. They're not going to write C for every one of those specific incidents. They're literally going to watch the behavior of the five star human drivers for enough hours and they're going to imitate it."}, {"speaker": "B", "start": 2438.81, "end": 2482.48, "text": "All right, but you're missing my point back on the, on the, on the Internet side, which is, is telling. Having the, having the AI like move my cursor around and click and fill out things is, is not the most, no, of course, efficient way to do this. You would, you would have API APIs, of course, with these different services and, and, and a way to interact and that's going to be a, an interesting evolution. And there's a number of startups working on this too, on different ways to try and drive action and to, you know, some of them will, will sit on top of browsers and do that, or some of them might try and sit on top of your phone. Of course Google and Apple will stop them from doing that."}, {"speaker": "A", "start": 2482.64, "end": 2521.23, "text": "I totally agree with that. It's funny, I was asking our analysts, right? 10 billion queries a day on Google today I say, do the number of queries in the future go up or go down, right? And I had somebody, if I saw Arvin at Perplexity, said to me, well, the number of queries probably goes down because you don't have to ask it so many times, it'll just give you an answer. And I said, what about the positive reflexivity? Once I get the answer, I've got more questions, right? Like as long as it's fast and it's producing that information, I actually think actions and memory will unlock more interactions because it's so much more valuable to me. I'll start using it more and more for these future things and I don't."}, {"speaker": "B", "start": 2521.23, "end": 2549.49, "text": "Know, it'd be interesting to see there, you know, for a while we've had the Alexis of the world or whatever, you know, do integrations, right? And so the, maybe the possibility exists that if I'm an Uber customer, an open table customer, that, that, that eventually I will tell them my favorite front end and they'll come to some agreement there so that they can pass my registration information through and that that all happens seamlessly. But there's a lot of work to do to make all that happen."}, {"speaker": "C", "start": 2549.49, "end": 2549.81, "text": "Right."}, {"speaker": "A", "start": 2549.81, "end": 2589.4, "text": "I mean, I, I think there's a lot of agent to agent interaction that will go on. An AI agent representing both of these parties. But what's interesting about the action model, you know, the hackiness that you talk about. Right. I imagine this will get solved by startups in some pretty hacky ways to begin, but then it will ultimately likely be solved at scale in more elegant ways, whether it's APIs or agent to agent interactions, et cetera. But we're starting to see real experimentation and I've had some of the early prototypes of actions actually coming to pass and that feels to me like the next two big breakthroughs are going to be this memory."}, {"speaker": "B", "start": 2589.48, "end": 2620.03, "text": "And by the way, I said this last time and, and, and I, it's a subtle point, but I don't think Google, you know, it's another issue in the, in the disruption. I don't think Google has treated its partners well in the search ecosystem. And so there's a lot of, of angst there and a lot of mistrust. And so if OpenAI or Perplexity came along and said, would you integrate and pass tokens? They might say yes. I think they're going to be more reluctant to do that with Google."}, {"speaker": "A", "start": 2620.03, "end": 2625.67, "text": "I mean, at a minimum, we know they would probably like more competitors in the game of sending them leads."}, {"speaker": "C", "start": 2625.75, "end": 2626.15, "text": "Right."}, {"speaker": "A", "start": 2626.31, "end": 2689.11, "text": "So I mean, I think just the fact that you're a smaller player, that you can be another source of competition and they're not so dependent on Google for upstream traffic is probably an advantage to you. Well, I know we're going to want to move to the topic of chips here in a second, but before we get there, we touched on Microsoft, we touched on Google, we touched on Apple just by way of comparison. And people have heard me talk about Meta a little bit in this regard. So again, the way we approach the analysis for all large cap tech, we said is their existing business get better or worse because of AI and then do their new business opportunities get bigger? Okay, so in the case of Meta, unlike Google, Google has this massive super profitable business that's under assault by answers and actions. In the case of Meta, we've seen their core business get better as a result of AI. Why? Because you're targeting videos now on reels, you're targeting."}, {"speaker": "B", "start": 2689.83, "end": 2692.07, "text": "That happened pre alum. That was already happening."}, {"speaker": "A", "start": 2692.07, "end": 2791.39, "text": "It was starting to happen. But the big difference really, I think between ByteDance and Meta was that Yeming at ByteDance adopted an approach around AI and GPUs before Meta did. And I think, I think Mark really made that transition about three years ago. You can see it in their capex spend. But the big question was obviously he had to spend the money before he got the results. And so investors like us were kind of holding our breath and we're saying, would this lead to better engagement? Well, now we know it's lead led to massively better engagement. And I'm not talking just on reels. This is on the core big blue Facebook product. This is on WhatsApp, this is on Instagram. So they have these big platforms that are benefiting from both more engagement and the targeting of ads. Remember this Stock was at 90 bucks and everybody said Facebook's dead because Apple attacked. Apple pushed through their changes that disabled their ability to really track people into what. And basically because of AI, they've been able to backfill that monetization completely. Nobody thought, no investors thought that was going to be the case 18 months ago. So their core business got a lot stronger. Now as we look ahead, think about the new business opportunities that are in front of them. And I'm just talking about the things that Mark's talked about on the call number one, they've got tens of millions of business customers that now they're literally creating these customer Service Agents for AI agents for every single WhatsApp business. Now we don't see that as much here in the US even though WhatsApp is the fastest growing messaging platform in the US but if you go to a place like India or Brazil, people are transacting some of the biggest AI engines."}, {"speaker": "C", "start": 2791.55, "end": 2791.95, "text": "Right?"}, {"speaker": "A", "start": 2792.03, "end": 2837.52, "text": "AI bot companies are being built on WhatsApp as a platform in Brazil and in India, where they have tens of millions of customers already using them. So these have become platform companies that are enabling vertical and horizontal bots. And they're going to build their own. They're going to build it for celebrities. They're going to build shopping agents that assist me buying things on Instagram. You know, I always see all these things I like on Instagram, but it's a pain to actually buy the things on Instagram. The one click never got that easy. Now I think you're going to see shopping agents that assist in doing that. And then just think about this content creation bill, whether you're an advertiser, just think what we saw this week with Sora text to video. I mean, now think of this in the context of an advertiser trying to drive emotions."}, {"speaker": "B", "start": 2837.52, "end": 2838.36, "text": "Or a creator."}, {"speaker": "A", "start": 2838.44, "end": 2925.87, "text": "Or a creator, Right? So my sons are creators, creators on these platforms. This is going to unleash monster amounts of creation in the world at lower costs. And so all of that, I think benefits their core business. You have these new businesses that they get to move into that I just mentioned. Then of course, I thought another interesting thing from Morning Brew, I think the pod that Mark was on last week, he talked about the meta AI glasses that all my analysts have. Right. He said, you know, most people, they looked at Mark taking the video, reviewing the Vision Pro from his couch and they see, you know, that got a lot of clamor on Twitter. But the fact of the matter is, Mark said the way you ought to think of VR and AR really is as your desktop or your laptop. But the meta AI glasses he said think of as your phone. Right, Because I'm going to be able to text, I'm going to be able to call, I'm going to be able to listen to music, I'm going to be able to order my Uber, I'm going to be able to do all these things from those glasses and I don't have to pull out this rectangular thing or I keep it in my pocket or whatever. I think that's why you're seeing such incredible demand for those. And of course the form factors will change and it'll evolve over time, but that's an entirely new line of business. So this is a company that's spending $20 billion a year on these other businesses that haven't been generating a lot of return. And I think now the market's starting to assign some value to those businesses."}, {"speaker": "B", "start": 2925.87, "end": 2947.18, "text": "But we, we should be fair, right? Like, cause YouTube benefits from those same dynamics that you talked about. And if you're talking about units of, of being the, the, the, the phone or the, like Apple and, and Google already have 100 huge install base like yes, what, four orders of magnitude to the number of Ray Ban glasses."}, {"speaker": "A", "start": 2947.18, "end": 2960.3, "text": "Yeah, no, no, no, for sure. But I think the question is from where you are today, right? And so like I'll stipulate YouTube will be a better business in the future. Content targeting will be better, ad targeting will be better."}, {"speaker": "C", "start": 2960.65, "end": 2960.89, "text": "Right."}, {"speaker": "A", "start": 2961.05, "end": 2985.05, "text": "And as long as Google is able to backfill the, the core of search like we just discussed, then it's going to be worth more in the future. There's no doubt about it. And of course, in terms of just their basic research and development around AI, what they did with Gemini 1.5, et cetera, I mean like these, they have incredible talent and resources. The only liability is they have an incumbent business that is a monopoly business with monopoly profits."}, {"speaker": "B", "start": 2985.05, "end": 2991.48, "text": "So, so that we can move on. Let's do a fast drive by. I'm going to do one on Apple and then you, and then you do Amazon."}, {"speaker": "A", "start": 2991.48, "end": 2996.16, "text": "So get as a reminder to everybody, just our opinions, not investment advice."}, {"speaker": "B", "start": 2996.56, "end": 3041.18, "text": "So for me, you know, Apple, you, you could argue they have the best asset in the world in this phone and it, and if you look at the user base of this compared to the Android user base, you know, it's just perfect. Right. And they, they have been doing Siri for a while and so you what, you connect those two things, you say shit like they put an LLM on top of this. They could get to all the data whether, I assure you, could give it permission to read your email. So you could literally get to all the data. So that's a massive positive. Now the negative is they haven't been known for Internet services. You look at Spotify relative to Amazon Music, Siri's kind of been, it's been terrible. Not evolving. Right. Like it's very much like it was the day it came out."}, {"speaker": "C", "start": 3041.18, "end": 3041.62, "text": "Yeah."}, {"speaker": "B", "start": 3041.62, "end": 3066.87, "text": "And so it would almost require a pivot of like, like Mark did on cost. You'd almost have to see Tim come out and say we're making a massive pivot like 180 degrees. We're going to be all in. Like, like we're putting our best engineers on this. And, and until that happens, I think it's a doubters camp."}, {"speaker": "A", "start": 3067.83, "end": 3071.43, "text": "Yeah, well, I mean clearly it's been an underperformer this year."}, {"speaker": "B", "start": 3073.06, "end": 3074.74, "text": "I mostly related to China market."}, {"speaker": "A", "start": 3074.82, "end": 3081.58, "text": "Yeah, yeah, you have China market, but you have all these concerns in the market going just as to what's the durability of revenue going to be in the future."}, {"speaker": "B", "start": 3081.58, "end": 3097.65, "text": "You clearly have, but they have the assets. Imagine if you took like five of the top AI people. I mean these companies and, and, and they were there. I'm like they were there the way Tony Fidel was there, you know, early on for the ipod. Like if you had that, you know."}, {"speaker": "A", "start": 3097.65, "end": 3109.29, "text": "Listen, for the first time they have real challengers whether it's a humane, a rabbit, a meta, AI glasses, these other things. Right. Like I'm just saying the door has been cracked on the ecosystem. Siri has not evolved."}, {"speaker": "C", "start": 3109.29, "end": 3109.61, "text": "Right."}, {"speaker": "A", "start": 3109.61, "end": 3152.64, "text": "So they, they, I think they're the first to acknowledge that. I think they are going to try to disrupt themselves about that. I'm not sure whether we'll see a big breakthrough moment this year. I think we'll definitely see announcements this year about AI on the Edge, running on the phone and, and all these other things. And we'll start to see, they'll start to crack the door on this. To me, the big breakthrough on Apple is if they can run a 5, $10 billion parameter model on the phone on the edge without consuming all of my battery, which, you know, there's a lot of talk that they're going to be able to do that. They can maintain some memory about me and then they can show me the early part of actions on this device. It will unlock a huge new device cycle. Okay. And that's what drives this stuff."}, {"speaker": "B", "start": 3152.8, "end": 3156.0, "text": "I was the one supposed to do you do."}, {"speaker": "A", "start": 3156.0, "end": 3156.44, "text": "No, no."}, {"speaker": "B", "start": 3156.44, "end": 3164.18, "text": "I'm, I'm going to ask you quick question. On the E commerce side of the business, does AI help or hurt Amazon? Yeah."}, {"speaker": "A", "start": 3164.18, "end": 3164.58, "text": "Okay."}, {"speaker": "B", "start": 3164.58, "end": 3165.14, "text": "And how much?"}, {"speaker": "A", "start": 3165.14, "end": 3269.26, "text": "Yeah, I think, I think on AI there, there are two. When I think about retail, E commerce, I think about it from two directions. First is Apple has been in the business of AI from a merchandising perspective just like Alibaba has been for a long time. Think about the largest retailer in the world, right? Think about the way Macy's used to work. There was somebody at the store who would say we're going to show black T shirts the front of the line at Amazon today. Nobody knows why they are targeting Brad Gerstner with certain things. It's a black box. Okay. So they're using it. But here's the thing. I, I, I think that is happening a bit to them on that front. And, and by the way, Andy Jassy is getting fit. They are tightening the screws on costs and all the other things. But look at a company like Temu, okay, that Pim Dodo in China owns that quickly became the largest advertiser on, on Facebook. Its E commerce sales are through the roof. Now what they're doing, I mean it's so incredibly clever. It's full stack AI so they don't even have inventory or merchandise. They literally go out and they, they collect data from customers about what they think they will want. They can assess how many of those things to build and they literally are building it for themselves. So they vertically integrated this AI E commerce business and then they're pushing it out the other end. And so I think there have been a lot of people in the US who have been dismissive but they've been shocked how big that business has come become in such a short period of time. We're starting to see this out of, out of tick tock as well where they're turning into an E commerce business. I think this opportunity sits in front of Meta as well. So I think there are some orthogonal challenges, but in terms of the core, I think their core continues to get better because of better targeting and, and AI reducing costs. Think about their customer care cost bill."}, {"speaker": "B", "start": 3269.26, "end": 3272.74, "text": "We do have to move on, hit AWS as quickly as possible."}, {"speaker": "A", "start": 3272.74, "end": 3281.58, "text": "Yeah. So I would, I would say aws. At the end of the day, these companies are in the business of renting AI services to end enterprises."}, {"speaker": "C", "start": 3281.9, "end": 3282.22, "text": "Right."}, {"speaker": "A", "start": 3282.22, "end": 3305.67, "text": "And as much as we talk about Azure and Microsoft running the table today, here's the truth. We've seen almost no share shift from AWS to Azure as a result of OpenAI. And if you would have asked me 12 months ago, I would have said jury's out as to whether or not that's going to happen. It didn't happen. Amazon responded quickly enough. And here's the other thing, you know, and Slootman's talk a lot about this term data gravity."}, {"speaker": "C", "start": 3306.07, "end": 3306.39, "text": "Right."}, {"speaker": "A", "start": 3306.39, "end": 3314.47, "text": "It turns out all my data's in aws. So long as they have a decent AI solution, I'm going to stick with them because I don't have to move anything. And I think they delivered that."}, {"speaker": "B", "start": 3314.47, "end": 3342.69, "text": "I listened to a podcast and Jassy was talking about the fact that they have proprietary chips for both training and inference. And obviously as the AWS stack grew up, they had moved into networking chips, they moved into a lot of technologies people wouldn't have thought about Amazon owning or designing. Do you give them. And this would be a good transition, do you give them any chance of being competitive in it from an AI silicon perspective?"}, {"speaker": "A", "start": 3343.89, "end": 3356.07, "text": "So I think the right way to think about it is not will they build a better GPU than Nvidia? The right way to think about it is can they supplant part of the supercomputer?"}, {"speaker": "C", "start": 3356.07, "end": 3356.31, "text": "Right."}, {"speaker": "A", "start": 3356.31, "end": 3381.61, "text": "The entire system? Are there pieces that they can pull out and plug in? Or workloads, specific workloads that they can serve with a lower cost infrastructure because they're doing hyper targeting silicon all the way to model. And I think the answer to that is yes. But I still think they'll be one of the largest buyers of Nvidia GPUs in the world because it doesn't replace that for a lot of really important work."}, {"speaker": "B", "start": 3381.69, "end": 3422.05, "text": "One thing he also said that I think would be good for the listeners to hear and you know, I don't want to overstate, you know where Alexa is and we talked about Siri earlier, but he said that as Alexa got bigger, that the training costs are tiny compared to the inference cost. And he suggested, and maybe this is me interpolating that the inference market over time is going to be much more susceptible to, you know, things that are lower power, lower cost, all the, all the things that aren't just performance from a, from a silicon perspective."}, {"speaker": "A", "start": 3422.13, "end": 3457.4, "text": "And I totally believe that to be true. And with that we can move to the biggest headlines of the week. We finally got here, which is this debate over the future of the compute build out needed to support AI. You know, to, to your earlier point about valuation. How unique is this revenue? How long does it last? And so we have a couple of charts just to bang or tweets to bang through here to kind of contextualize this. First, Nvidia stocks up a lot, but it's because the revenue and the profits have greatly exceeded expectations. So this chart just shows what their data center market share has grown to in the year."}, {"speaker": "C", "start": 3457.4, "end": 3457.8, "text": "Right."}, {"speaker": "A", "start": 3458.2, "end": 3510.78, "text": "The world is shifting toward AI as a compute infrastructure and they've benefited. One of the areas I think I tweeted about this, that I think has been greatly underestimated, this idea of sovereign demand. And I tweeted this week, you know, I think Jensen was over in the Middle east meeting with, with several of the GCC countries over there and I think what people still don't appreciate is they're probably dozens of sovereigns who are trying to get into the Nvidia order book and that they view it as one of their top three national priorities to build out AI capabilities. And I think the size you're talking about for some of these GCC countries is going to be competitors competitive with the hyperscalers itself. So in that context, right. When Sam Altman suggested and blew everybody's mind that he was going to raise $7 trillion to, you know, build chips."}, {"speaker": "B", "start": 3510.78, "end": 3515.42, "text": "I don't know if he ever said, was inferred and repeated over and over and over again."}, {"speaker": "A", "start": 3515.42, "end": 3549.2, "text": "So he threw out a big number. But I do think that we're talking trillions of dollars over the course of the next four to five years as we rebuild the world's compute infrastructure. And then finally Masa did not want to be left out and so he came out and said that he's going to raise a hundred billion dollars to build fabs and chips to compete with Nvidia as well. You've watched the semi industry for a long time. Okay, and, and more importantly, just the dynamics of supply and demand. So just step back for a second. Right. What do you make of all of this?"}, {"speaker": "B", "start": 3550.0, "end": 3619.01, "text": "Well, I have some cynicism but, but that comes naturally to me. The first thing I would say is they're, they're all talking about raising money from the exact same people. So if I were those people, I would just be a little careful because I think to a certain extent there's a, there's a smell of loose money or that, that's how I would interpret it because they're not, they're not saying they want to raise this money. Absolutely. They're saying they want to raise it from a very specific group in the Middle East. Yeah, so, so that's one thing too. I was struck when I read about sovereign server stacks. You know, there needs to be a reason. Right. It would have to be about, you know, wanting to have control over certain amounts of information. It could be proprietary information to your country, could be wanting to control how LLMs operate. Country servers typically depreciate a bit like fish, you know, and, and, and, and that's been true of DRAM and storage and all."}, {"speaker": "A", "start": 3619.17, "end": 3619.97, "text": "You said fish."}, {"speaker": "B", "start": 3619.97, "end": 3621.33, "text": "Right, Fish. Okay."}, {"speaker": "A", "start": 3621.57, "end": 3622.93, "text": "They last a day, like."}, {"speaker": "B", "start": 3622.93, "end": 3703.86, "text": "Yeah, well, I mean it's, it's, I'm being provocative, obviously, but people have talked about with that, with those, like you would, you wouldn't want to hoard any. Because what happens is, you know, the next generation comes along and it goes down quickly. So I, I would just, you know, there was a time at which Microsoft was trying to convince the world that we'd all need an NT server for every employee. And you know, when I heard that the first time, I was like trying to get like twist my head. So I don't know. I don't know if countries need server stacks. Maybe, like I said, it'd have to have those particular frames in mind. The second thing that just struck me, and this gets more to the Altman and the MASA quote, is the idea that we're just going to go compete with Nvidia is pretty radical. There are already people competing with Nvidia. AMD's competing with Nvidia. There are other people that have somewhat of a head start, like decades. Yeah. So you're just going to go do it. That's bold. It's not like chip design bins. Oh, oh yeah. And intel, obviously. But like, it's not like chip design bins to disruption or like software does like this is hard stuff."}, {"speaker": "C", "start": 3703.86, "end": 3704.26, "text": "Yeah."}, {"speaker": "B", "start": 3704.26, "end": 3755.42, "text": "And then some of them. And I once again, I don't know that there was an exact quote, but the idea that you're going to build a fab and compete, you're going to compete with TSMC and Nvidia at the same time. Like no chance. Yeah, like no chance. Because like let's say, let's say you got it. I mean we all know how the math works. But say you got a 20 chance of competing with either of them, right? Like then you're down to four like a pulling this off. And by the way, the time scale that you're going to need, like it, I mean just read. Well, we'll get into it in a minute because we'll talk about like what it means to have a competitive fab around the world. But TSMC is far, far ahead of the competition. And one of the reasons AMD has a higher market cap than intel today is specifically because they got out of the fab business and bet on tsmc."}, {"speaker": "A", "start": 3755.9, "end": 3758.82, "text": "So I think, I think it's really important to tease out those two things."}, {"speaker": "C", "start": 3758.82, "end": 3759.18, "text": "Right?"}, {"speaker": "A", "start": 3759.42, "end": 3840.89, "text": "There's chip design, right? And obviously Nvidia is already designing for two to three generations ahead. I mean the Series B is already taking orders in the order book, likely to launch in Q3 of this year and you know is order of magnitudes better than the H1 hundreds that are out there today. And then you're, they're already designing what comes after Blackwell. And so it's not as though they're standing still. And anybody who knows Jensen, he's an animal and that that company is, is playing for the future. And then if you look at TSMC and I shared with you a video, maybe just pull up a little bit about kind of the findings from that. But this is from the founder of TSMC and the CEO for decades, Morris, changing, talking about the competitive advantages and Bill, because this really gets to the fab, like why are all the world's fabs in Taiwan? Okay. And why aren't the fabs in Texas anymore with Texas Instruments? Or why aren't the fabs in other parts of the world and what does that mean for the future of this build out? And I think the implication of these, of these releases is that we're going to start building a bunch of fabs in the Middle East. I think we know we're trying to build fabs in Arizona. There's some talk about building fabs in Mexico, but maybe just let's deconstruct that one. What does it mean to build a fab outside of Taiwan to make next generation AI chips?"}, {"speaker": "B", "start": 3841.05, "end": 3890.83, "text": "You shared this link with me and I. It's a talk that Morris chang gave at MIT I think in November. Right. Very recently. He's over 90 and the first, it's like an hour long talk in the first 60% is a history lesson, but then the last 40%, I would encourage everyone to go watch, like everyone, including every politician in the United States of America. Because Morris makes the point that the reason Taiwan is competitive has to do with the labor model that exists there and the type of work people are willing to do and your ability to retain them. And he walks through his history of hiring in Texas and other parts of."}, {"speaker": "A", "start": 3890.83, "end": 3901.75, "text": "The U.S. yeah, interestingly enough, he ran a fab plant for Texas Instruments in Texas. And he explains why Taiwan, like why Texas could never possibly compete with a fab plant in Taiwan."}, {"speaker": "B", "start": 3901.75, "end": 3918.21, "text": "And, and he, even I, he, he admits that, that US was a manufacturing prowess in the 50s and 60s. But the, but, but the social requirements that we put on labor at that time are different than they are today."}, {"speaker": "C", "start": 3918.37, "end": 3918.85, "text": "Yes."}, {"speaker": "B", "start": 3918.85, "end": 3940.76, "text": "And so whether you look at TSMC and it turns out the same thing's true of a Foxconn factory in, in Mexico, you have people working longer hours, sometimes living in dormitories. And he mentions that in his talk and he says the country must more likely to disrupt Taiwan would be Vietnam or India."}, {"speaker": "C", "start": 3940.92, "end": 3941.4, "text": "Yes."}, {"speaker": "B", "start": 3941.56, "end": 3952.6, "text": "Not an advanced culture. And to think you're going to re onshore a fab and ignore Morris Chang is just kind of crazy to me."}, {"speaker": "C", "start": 3952.6, "end": 3952.92, "text": "Right."}, {"speaker": "B", "start": 3953.0, "end": 3978.88, "text": "And I look at the requirements once again that we put on companies around labor and say to myself, it's not going to happen here. And, and the people will quickly react to that and say, oh, you're in favor of, of forced labor or like super hard labor. But the people that are choosing that at that point in time are choosing a better life."}, {"speaker": "C", "start": 3978.96, "end": 3979.32, "text": "Right."}, {"speaker": "B", "start": 3979.32, "end": 3990.99, "text": "And to deny them that opportunity, like the, the, the, the individual that lives in Juarez that's commuting to this Foxconn plant is getting a better life."}, {"speaker": "A", "start": 3990.99, "end": 3991.47, "text": "That's right."}, {"speaker": "B", "start": 3991.47, "end": 4004.59, "text": "With even with his four nights a week in the dorm. And to deny him that and insist on our circa 2023 social norms on that country is unfair."}, {"speaker": "C", "start": 4004.59, "end": 4004.91, "text": "Right."}, {"speaker": "B", "start": 4004.91, "end": 4005.87, "text": "From my point of view."}, {"speaker": "C", "start": 4005.87, "end": 4006.07, "text": "Right."}, {"speaker": "B", "start": 4006.07, "end": 4009.07, "text": "And denies them their chance at disruption."}, {"speaker": "A", "start": 4009.31, "end": 4035.87, "text": "So when you unpack, and we'll put the link to the video here, when you unpack that message, it's really that Taiwan thrived because these operators and technicians would spend their life working in the same fab on this. Getting, getting better and better at the same thing. And he Talked about a 12% churn rate, I think when he was at the fab in, in Texas. And he said the problem is the second a better job would come along, they would leave for a better job."}, {"speaker": "B", "start": 4035.949, "end": 4038.67, "text": "That was, it was 12 during, during a recession."}, {"speaker": "A", "start": 4038.67, "end": 4041.07, "text": "During 12 during a recession, implying that it was much higher."}, {"speaker": "B", "start": 4041.07, "end": 4044.95, "text": "It was with the 25. When, when, when times were good, economy was good."}, {"speaker": "A", "start": 4044.95, "end": 4075.61, "text": "And he said, you just can't run a fab plant with 25% churn among the operators. You, you produce really bad product. And I think the point is it's not just better life, it's also kind of these cultural norms. And so that's why he said, you know, in Vietnam and India they have cultural norms, he believes, that are more consistent with, with loyalty and staying with something longer. And on top of that, that it would be an improvement in the quality of life for the people who would take these jobs and therefore the incentive is there for them to stay in."}, {"speaker": "B", "start": 4075.61, "end": 4099.49, "text": "Those positions either right nor wrong. Like I, you know, I'm not, not provocative, like. Yeah, it's provocative because it says that if America is really worried about the concentration in Taiwan, they should probably be trying to help build semiconductor plants in Mexico or Vietnam or that kind of thing versus bringing them here because the odds of operating them here in a competitive way, globally competitive way, are low."}, {"speaker": "A", "start": 4099.57, "end": 4124.51, "text": "So I guess does that make you skeptical of the CHIPS Act? I mean, I see that intel is back in Washington looking for another $10 billion to subs the work that they're doing. I mean, I get the US national security concern, particularly considering that a hundred % or virtually 100% of these advanced chips are being manufactured in a place that has risk, has political risk associated with it. Bill, let me ask you this, by the way."}, {"speaker": "B", "start": 4124.91, "end": 4155.31, "text": "I am, I am somewhat skeptical of CHIPS Act. And then the other thing I would say to you is like, China's probably in a really good place. Yeah, they're really smart. They have all the intellectual capability of being competitive and they probably still have this opportunity for them, you know, over time in terms of the willingness of certain part of their population to be willing to work in those types of situations."}, {"speaker": "A", "start": 4155.31, "end": 4212.7, "text": "Yeah, I mean, I'll take probably the under on that. I think that the opportunity like now there is a global imperative to diversify the source of manufacturing. And I think Morris Chang was having this conversation at MIT recently because he understands the global imperative. I think you are going to see plants that get built in places like Vietnam and Japan. I think you are going to see them get built in India. You're probably going to see some attempts in the Middle East. Obviously we're trying to do some of this stuff here. I think from a United States interest, both in terms of wanting to maintain leadership in AI and wanting to diversify our political risk associated with Taiwan. It's not so important that everything is produced in the U.S. right. That shouldn't be our goal or objective for all the reasons that Morris Chang points out. But I do think it would be better if we had four or five places around the world that were load balancing the manufacturing of these."}, {"speaker": "B", "start": 4213.18, "end": 4255.5, "text": "That's a fair point. And I think the whole re onshoring think argument conflates the national security interest with a, with a interest in American jobs and that kind of thing going back quickly to these new chip companies that are going to miraculously compete with Nvidia. I, I would, I would tell you if, if, and this is maybe, you know, an older venture capitalist talking and one who's watched different partners sit on the boards of, of startup semiconductor companies. It ain't easy, you know. And you know, the, the first silicon that comes back doesn't always work."}, {"speaker": "C", "start": 4255.58, "end": 4256.02, "text": "Yeah."}, {"speaker": "B", "start": 4256.02, "end": 4260.38, "text": "And you might be 50 million to first silicon, you might be a hundred million to first silicon."}, {"speaker": "C", "start": 4260.38, "end": 4260.7, "text": "Right."}, {"speaker": "B", "start": 4260.78, "end": 4263.26, "text": "You've got to get in line at TSMC."}, {"speaker": "C", "start": 4263.34, "end": 4263.74, "text": "Right."}, {"speaker": "B", "start": 4263.74, "end": 4270.97, "text": "How are you going to break that door down? How are you going to out compete beat Nvidia for TSMC's time?"}, {"speaker": "C", "start": 4271.13, "end": 4271.53, "text": "Right."}, {"speaker": "B", "start": 4271.61, "end": 4282.01, "text": "Like how are you gonna get on that place? And it's hard. And by the way, once you do get working silicon, your yields are probably crappy."}, {"speaker": "C", "start": 4282.01, "end": 4282.53, "text": "Yeah."}, {"speaker": "B", "start": 4282.53, "end": 4290.01, "text": "Like that's what happens. Like this is, this is physical material science type stuff. It's not software."}, {"speaker": "C", "start": 4290.09, "end": 4290.41, "text": "Right."}, {"speaker": "A", "start": 4290.41, "end": 4315.43, "text": "And you're going up against again two companies that are running in pretty exceptional ways by exceptional founders. In the case of Jensen has been there for three decades. He's devoted his life to this. TSMC seemingly has similar types of leadership. But one of the things I wanted to pivot to on this bill because it begs the question why is Sam throwing out this really big number?"}, {"speaker": "C", "start": 4315.91, "end": 4316.31, "text": "Right."}, {"speaker": "A", "start": 4316.55, "end": 4605.87, "text": "Why is Masa throwing out this really big number? And I think the answer, like one of the things I want to talk about is this, which is just what is the size of the market opportunity that we're talking about here? And so I have a slide. We had Jensen when he was in the Middle east, he mentioned, and the quote was, and this was just from February 24, he said there's about a trillion dollars worth of installed base of data centers around the world. And over the course of the next four to five years we'll have 2 trillion of data centers powering software around the world and it will all be accelerated compute. Okay. And so I asked my team to break that down a little Bit like what, you know, how does that look like per year, right. To get to this number. So of course I'm doing this from outside in. We take a swag at it and it pulls up this next line bar chart. So this is the AI data center build out. In blue is the new accelerated computer, right. In green is the replacement data center that we think will go to accelerated and then in gray is the replacement that's non accelerated compute. So this would be more like, you know, x86. And again I'm certain this is wrong specifically, but that's what we're in the business of doing, trying to build a forecast based upon folks who are providing this information. The line running through the center that starts at 55% and goes down to 26%, that is Nvidia's share of that global compute build out based on current consensus numbers for Nvidia, okay, so the consensus forecast that has the stock at $700 a share assumes, if you believe this TAM to be accurate, assumes that their share will go from 55% today to 26% in 2028. Now I think if you just step back and you say okay, do we think we're going to go from a trillion of data centers to 2 trillion of data centers? Just ask that at a high level. Okay, well you and I just spent an hour plus talking about how a 10 billion queries a day are likely to move from information retrieval right. To inference as we as humans expect to get answers rather than a card catalog. We talked about enterprises, whether they're doing their engineers in co generation or whether customer service centers or whether Tesla and full self driving or whether it's sovereigns who are taking on national security issues, you know, drone fleets, or whether it's proteins and life sciences or material sciences. There isn't going to be a single industry on the planet that's not employing accelerated computer in order to solve the problems of their enterprise. So if you said to me with that as the backdrop a year ago, I think the big question bill was is there going to be enough productivity gains in the world to justify this compute build out? Remember people thought oh, we're pulling forward all the demand for Nvidia. This is like dark fiber in 2000. We're going to be way oversupplied, we're going to have a glut. I think the evidence on the field is that that was wrong. I think the evidence on the field is that in fact, just like we talked about on the last pod, we tend to underestimate the size of these super cycles. Because when you have these phase shifts, everything changes. You have positive reflexivity in the world. More begets more because it's better, right? And so I think the bigger question when I look at this chart and what I push my team on, what I'm certain of, you know, when I the rumored pricing of H1 hundreds to B1 hundreds, is that B1 hundreds are going to cost even more than the H1 hundreds. And so I say to my team like these margins have to get competed down, right? But the feedback and something I think that's really important is that although the B100 is more expensive, it's so much more powerful, right? It's like this if, if you had an employee bill and you were paying him a hundred thousand dollars and I said hey, you ought to hire this other guy, he cost 200,000. You said well why would I hire him if he costs 200,000? I would say he does 10x the work of the guy who, who you pay a hundred thousand to. You would pay him $200,000 in a second, right? And I think that's why Nvidia today is getting those margins. In the future I expect that there's going to be more competition whether it comes from this custom chips that you're talking about, whether it's from other competitors like amd, whether it's from, you know, new startups that, from Masa or Sam, et cetera. But you and I just talked about the challenge to build a fab and the challenge to design those chips is non trivial and you know, the probabilities are somewhat low and so it's going to take time to get time."}, {"speaker": "B", "start": 4605.87, "end": 4621.76, "text": "I mean if you're starting today like when would you have an impact? But one question I would have for you on this is, you know, if you're right about this, I wonder about TSMC's capacity, right? You know, and that is a limiter to this, right?"}, {"speaker": "A", "start": 4621.76, "end": 4701.29, "text": "So you're looking at the chart and saying how do we get to 2 trillion of replacement in new if TSMC is gated in their ability to produce these. Now Jensen gave this number, he's intimately familiar with TSMC and their ability to produce. So I said I, I think he has a sense of, in his head about what they can get done. I think that the other limit limiting factor we're going to run up against here pretty quick, it's not going to be capital, right? It may or may not be TSMC, but the power consumption. So even for the B100, the data center designs like you're talking about liquid cooling, custom designed data centers, they're going to consume massive amounts of power. And I think part of the reason you're hearing about this sovereign demand from the Middle East Bill, is they understand that their chief competitive advantage is low cost energy, right? And I don't think they're talking about building all of this just to service the needs of their country. I think they're smart enough to understand they're trying to equitize all their petrochemical wealth into technology wealth in the future. And if I was running one of those countries, I would look at this phase shift as an opportunity to become the supplier to the world of, of, of computer aided intelligence."}, {"speaker": "C", "start": 4701.45, "end": 4701.85, "text": "Right?"}, {"speaker": "A", "start": 4702.33, "end": 4777.19, "text": "And if they can do that because they have lower cost energy and because they can recruit the likes of Sam Altman, they can recruit the likes of TSMC to their countries to set up shop there, to design chips there, it's not all that different than digging wells, right? Think about digging a well. You have to spend a lot of money, a lot of time, a lot of research. You're hoping you get your payback 5, 10, 15 years into the future. And so I think this is a rational decision by them to build out this capability. But to your point, it's a non zero and non trivial undertaking to try to get it done. Now if they do that, it's going to put them in competition with some of the hyperscalers, right? From core weave to AWS to others who are in the business of renting AI capabilities out. But I think it's good for the world because what we want to see is a lot of competition. We want to see the price of AI compute fall over time. That's going to lead to a lot more consumption. And because of the productivity gains from the end applications again, self driving cars or coming up with vaccines or solving complex problems or just allowing consumers to have answers instead of 10 blue links. We need the cost to come down on all this stuff."}, {"speaker": "B", "start": 4777.19, "end": 4796.22, "text": "If you, and maybe this would be a good way to wrap, but if you, if you bring that, that attitude to the table, I mean it sounds like, and I don't want to put words in your mouth, but there's no, there's no reasonable end in sight from where you sit like on this wave. We're at the very beginning and it's going to go for a long."}, {"speaker": "A", "start": 4796.22, "end": 4843.24, "text": "I said last week and I think we had a little video that went out and I said we are going to hit a zone of disillusionment. I don't know whether it's this quarter, maybe tomorrow with Nvidia when it starts, right. We're going to hit a zone of disillusionment where you have a mismatch between supply and demand. And then all the skeptics are going to say, I told you so. The Internet's a fad. AI is a fad. Mobile's a fad. Like it happens in every super cycle. We're going to use that as a buying opportunity because we are absolutely convinced that the Runway is longer and wider and the impact on humanity is going to be greater because the end applications are so compelling that are using AI to assist them in everything that they do. But that's really where the tug of war is in the world today, Bill. And that's what makes a market."}, {"speaker": "C", "start": 4843.72, "end": 4844.08, "text": "Right?"}, {"speaker": "A", "start": 4844.08, "end": 4852.6, "text": "You're gonna have those people who are skeptics about that demand. That's what creates a wall of worry. You know. Why does Nvidia trade at 20 to 30 times earnings?"}, {"speaker": "C", "start": 4852.76, "end": 4853.08, "text": "Right."}, {"speaker": "A", "start": 4853.08, "end": 4859.8, "text": "I would say because there's a lot of skeptics and there's a lot of worry about whether or not these free cash flow is durable into the future."}, {"speaker": "C", "start": 4859.96, "end": 4860.36, "text": "Right."}, {"speaker": "B", "start": 4860.68, "end": 4863.0, "text": "I bet you the worry's more on pricing than volume."}, {"speaker": "C", "start": 4863.0, "end": 4863.24, "text": "Right."}, {"speaker": "A", "start": 4863.24, "end": 4866.1, "text": "And by the way. And it's, it's unknowable."}, {"speaker": "B", "start": 4866.1, "end": 4866.34, "text": "Right?"}, {"speaker": "A", "start": 4866.34, "end": 4882.86, "text": "Like I don't know. Nobody who follows this knows. So you have to assign some probability to that future outcome. But I think you're right. It is a good place to leave it. I wish you could be here. I know you're, you're, you're anchored down there in Texas. Speaking of Texas fabs. But this is fun to have you here in person."}, {"speaker": "B", "start": 4882.86, "end": 4883.66, "text": "Good to see you."}, {"speaker": "A", "start": 4883.74, "end": 4891.7, "text": "Like old times. And, and I think we're going to be talking and debating this for as long as we're doing this pod for sure."}, {"speaker": "B", "start": 4891.7, "end": 4892.14, "text": "No doubt."}], "video_path": "backend/data/-i9AGk3DJ90.mp4"}